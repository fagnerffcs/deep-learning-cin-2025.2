{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWnpmRWVumhd"
      },
      "source": [
        "0. Instalando pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YKrOmWIEutGN",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e86d8f-9d9e-49b5-de84-9e52fb3c738a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ torch: 2.6.0+cu124 â†’ 2.3.0\n",
            "âŒ transformers: 4.52.4 â†’ 4.51.3\n",
            "âœ… peft: 0.15.2\n",
            "âŒ sentence-transformers: 4.1.0 â†’ 2.5.1\n",
            "\n",
            "ğŸ”„ Reinstalando 3 pacote(s)...\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Successfully uninstalled transformers-4.52.4\n",
            "Found existing installation: sentence-transformers 4.1.0\n",
            "Uninstalling sentence-transformers-4.1.0:\n",
            "  Successfully uninstalled sentence-transformers-4.1.0\n",
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.18.0\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchaudio==2.3.0\n",
            "  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.15.2 requires transformers, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0\n",
            "Collecting transformers==4.51.3\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2025.4.26)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "Successfully installed transformers-4.51.3\n",
            "Collecting sentence-transformers==2.5.1\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (1.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers==2.5.1) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.5.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.5.1) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.5.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.11.0->sentence-transformers==2.5.1) (1.3.0)\n",
            "Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.5.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.2.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=3c3aec079985fe16e78e2a563e2c83d831cdbd021f0f572b46195edc81483ccd\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: colorlog, alembic, optuna, lime\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 lime-0.2.0.1 optuna-4.4.0\n",
            "âœ… ReinstalaÃ§Ã£o concluÃ­da!\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# VERIFICAÃ‡ÃƒO INTELIGENTE DE PACOTES\n",
        "# ================================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def smart_package_check():\n",
        "    \"\"\"Verifica e instala apenas pacotes necessÃ¡rios\"\"\"\n",
        "\n",
        "    # VersÃµes desejadas\n",
        "    target_versions = {\n",
        "        'torch': '2.3.0',\n",
        "        'transformers': '4.51.3',\n",
        "        'peft': '0.15.2',\n",
        "        'sentence-transformers': '2.5.1'\n",
        "    }\n",
        "\n",
        "    needs_reinstall = []\n",
        "\n",
        "    # Verificar cada pacote\n",
        "    for package, target_version in target_versions.items():\n",
        "        try:\n",
        "            result = subprocess.run([sys.executable, '-c',\n",
        "                f\"import {package.replace('-', '_')}; print({package.replace('-', '_')}.__version__)\"],\n",
        "                capture_output=True, text=True)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                current_version = result.stdout.strip()\n",
        "                if current_version != target_version:\n",
        "                    print(f\"âŒ {package}: {current_version} â†’ {target_version}\")\n",
        "                    needs_reinstall.append(package)\n",
        "                else:\n",
        "                    print(f\"âœ… {package}: {current_version}\")\n",
        "            else:\n",
        "                print(f\"âŒ {package}: nÃ£o instalado\")\n",
        "                needs_reinstall.append(package)\n",
        "        except:\n",
        "            print(f\"âŒ {package}: erro na verificaÃ§Ã£o\")\n",
        "            needs_reinstall.append(package)\n",
        "\n",
        "    # Reinstalar apenas se necessÃ¡rio\n",
        "    if needs_reinstall:\n",
        "        print(f\"\\nğŸ”„ Reinstalando {len(needs_reinstall)} pacote(s)...\")\n",
        "\n",
        "        # Desinstalar\n",
        "        !pip uninstall -y {' '.join(needs_reinstall)}\n",
        "\n",
        "        # Reinstalar com versÃµes corretas\n",
        "        if 'torch' in needs_reinstall:\n",
        "            !pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0\n",
        "        if 'transformers' in needs_reinstall:\n",
        "            !pip install transformers==4.51.3\n",
        "        if 'peft' in needs_reinstall:\n",
        "            !pip install peft==0.15.2\n",
        "        if 'sentence-transformers' in needs_reinstall:\n",
        "            !pip install sentence-transformers==2.5.1\n",
        "\n",
        "        # Instalar pacotes adicionais\n",
        "        !pip install optuna shap lime wordcloud\n",
        "\n",
        "        print(\"âœ… ReinstalaÃ§Ã£o concluÃ­da!\")\n",
        "    else:\n",
        "        # Verificar pacotes adicionais\n",
        "        additional = ['optuna', 'shap', 'lime', 'wordcloud']\n",
        "        missing = []\n",
        "\n",
        "        for pkg in additional:\n",
        "            try:\n",
        "                __import__(pkg.replace('-', '_'))\n",
        "                print(f\"âœ… {pkg}: instalado\")\n",
        "            except ImportError:\n",
        "                missing.append(pkg)\n",
        "\n",
        "        if missing:\n",
        "            print(f\"ğŸ“¦ Instalando pacotes adicionais: {missing}\")\n",
        "            !pip install {' '.join(missing)}\n",
        "        else:\n",
        "            print(\"ğŸ‰ Todos os pacotes jÃ¡ estÃ£o corretos!\")\n",
        "\n",
        "# Executar verificaÃ§Ã£o\n",
        "smart_package_check()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importando pacotes"
      ],
      "metadata": {
        "id": "tQyi3HYIi0Q5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u65aY4nXrvHo"
      },
      "outputs": [],
      "source": [
        "# 1. Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WPlYWE1fupwV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoJCP_OXr2R3"
      },
      "source": [
        "# 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# MONTAR GOOGLE DRIVE CORRETAMENTE\n",
        "# ================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Montar o Google Drive na raiz\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Definir o caminho para seu projeto\n",
        "project_path = '/content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto'\n",
        "\n",
        "# 3. Verificar se o diretÃ³rio existe\n",
        "if os.path.exists(project_path):\n",
        "    print(f\"âœ… DiretÃ³rio encontrado: {project_path}\")\n",
        "\n",
        "    # Navegar para o diretÃ³rio do projeto\n",
        "    os.chdir(project_path)\n",
        "    print(f\"ğŸ“ DiretÃ³rio atual: {os.getcwd()}\")\n",
        "\n",
        "    # Listar arquivos no diretÃ³rio\n",
        "    print(\"\\nğŸ“‹ Arquivos no diretÃ³rio:\")\n",
        "    for item in os.listdir('.'):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "else:\n",
        "    print(f\"âŒ DiretÃ³rio nÃ£o encontrado: {project_path}\")\n",
        "    print(\"\\nğŸ” Verificando estrutura do Drive...\")\n",
        "\n",
        "    # Verificar estrutura do Drive\n",
        "    base_path = '/content/drive/MyDrive'\n",
        "    if os.path.exists(base_path):\n",
        "        print(f\"\\nğŸ“ ConteÃºdo de {base_path}:\")\n",
        "        for item in os.listdir(base_path):\n",
        "            print(f\"  - {item}\")\n",
        "\n",
        "    # Criar diretÃ³rio se nÃ£o existir\n",
        "    print(f\"\\nğŸ”§ Criando diretÃ³rio: {project_path}\")\n",
        "    os.makedirs(project_path, exist_ok=True)\n",
        "    os.chdir(project_path)\n",
        "    print(\"âœ… DiretÃ³rio criado e definido como atual\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SgQH75YHr3D",
        "outputId": "accf8ac7-2519-47ee-b726-3f44bfe1a425"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "âœ… DiretÃ³rio encontrado: /content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto\n",
            "ğŸ“ DiretÃ³rio atual: /content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto\n",
            "\n",
            "ğŸ“‹ Arquivos no diretÃ³rio:\n",
            "  - Detection of fake news using deep learning CNNâ€“RNN based methods.pdf\n",
            "  - fake-news-classifier-naive-bayes.ipynb\n",
            "  - classificacao_fake_news_multimodelos-1.pdf\n",
            "  - Fake News Dataset.zip\n",
            "  - fake_news_dataset_multimodel.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAVVX3Y9z3A4",
        "outputId": "552775b3-321e-4ad1-d901-20b822b87e3b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Carregando dataset com verificaÃ§Ã£o de cache...\n",
            "ğŸ“ DiretÃ³rio do projeto: /content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto\n",
            "ğŸ“¦ Arquivo ZIP: Fake News Dataset.zip\n",
            "ğŸ’¾ Arquivo processado: fake_news_processed.csv\n",
            "\n",
            "============================================================\n",
            "ğŸ§  SISTEMA DE CACHE INTELIGENTE\n",
            "============================================================\n",
            "âœ… Dataset processado encontrado e atualizado\n",
            "âš¡ Usando dataset em cache...\n",
            "ğŸ“Š Carregando dataset processado...\n",
            "âœ… Dataset carregado: 76,537 registros\n",
            "âœ… Dataset carregado do cache com sucesso!\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š DATASET CARREGADO COM SUCESSO!\n",
            "============================================================\n",
            "ğŸ“ Fonte: ğŸ’¾ CACHE\n",
            "ğŸ“Š EstatÃ­sticas:\n",
            "   - Total de registros: 76,537\n",
            "   - 0 (Fake): 38,434 registros (50.2%)\n",
            "   - 1 (Real): 38,103 registros (49.8%)\n",
            "   - Comprimento mÃ©dio do texto: 2197.3 caracteres\n",
            "\n",
            "âš¡ Vantagens do cache:\n",
            "   - Carregamento instantÃ¢neo\n",
            "   - Sem necessidade de reprocessamento\n",
            "   - Dados jÃ¡ limpos e validados\n",
            "============================================================\n",
            "\n",
            "ğŸ“‹ Exemplos dos dados:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ğŸ·ï¸  FAKE NEWS:\n",
            "   ğŸ“„ finally get work post november davidswanson dear democrat find suddenly bit doubtful wisdom drone war presidential war without congress massive investment new small usable nuclear weapon expansion bas...\n",
            "\n",
            "ğŸ·ï¸  REAL NEWS:\n",
            "   ğŸ“„ putin tell merkel un peacekeeper could deploy donbas contact line moscow reuters russian president vladimir putin told german chancellor angela merkel monday un peacekeeper might deploy eastern ukrain...\n",
            "--------------------------------------------------------------------------------\n",
            "ğŸ‰ Dataset pronto para uso! VariÃ¡vel 'data' contÃ©m 76,537 registros\n",
            "\n",
            "ğŸ’¡ Para forÃ§ar reprocessamento, execute: data, from_cache = force_reprocess()\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# CARREGAR DATASET COM CACHE INTELIGENTE\n",
        "# ================================================\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"ğŸš€ Carregando dataset com verificaÃ§Ã£o de cache...\")\n",
        "\n",
        "# ================================================\n",
        "# 1. CONFIGURAR CAMINHOS (VARIÃVEIS GLOBAIS)\n",
        "# ================================================\n",
        "\n",
        "# Caminhos no Google Drive\n",
        "project_dir = '/content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto'\n",
        "drive_zip_path = os.path.join(project_dir, 'Fake News Dataset.zip')\n",
        "processed_csv_path = os.path.join(project_dir, 'fake_news_processed.csv')\n",
        "metadata_path = os.path.join(project_dir, 'dataset_metadata.txt')\n",
        "\n",
        "# DiretÃ³rio temporÃ¡rio para extraÃ§Ã£o\n",
        "extract_dir = '/tmp/fake_news_data'\n",
        "\n",
        "print(f\"ğŸ“ DiretÃ³rio do projeto: {project_dir}\")\n",
        "print(f\"ğŸ“¦ Arquivo ZIP: {os.path.basename(drive_zip_path)}\")\n",
        "print(f\"ğŸ’¾ Arquivo processado: {os.path.basename(processed_csv_path)}\")\n",
        "\n",
        "# ================================================\n",
        "# 2. VERIFICAR SE DATASET PROCESSADO JÃ EXISTE\n",
        "# ================================================\n",
        "\n",
        "def check_processed_dataset():\n",
        "    \"\"\"Verifica se o dataset processado jÃ¡ existe e estÃ¡ atualizado\"\"\"\n",
        "\n",
        "    if not os.path.exists(processed_csv_path):\n",
        "        print(\"âŒ Dataset processado nÃ£o encontrado\")\n",
        "        return False\n",
        "\n",
        "    if not os.path.exists(drive_zip_path):\n",
        "        print(\"âš ï¸  Arquivo ZIP original nÃ£o encontrado, mas dataset processado existe\")\n",
        "        return True\n",
        "\n",
        "    # Comparar datas de modificaÃ§Ã£o\n",
        "    zip_mtime = os.path.getmtime(drive_zip_path)\n",
        "    csv_mtime = os.path.getmtime(processed_csv_path)\n",
        "\n",
        "    if zip_mtime > csv_mtime:\n",
        "        print(\"âš ï¸  Arquivo ZIP Ã© mais recente que o dataset processado\")\n",
        "        return False\n",
        "\n",
        "    # Verificar se o arquivo nÃ£o estÃ¡ vazio\n",
        "    try:\n",
        "        df_test = pd.read_csv(processed_csv_path, nrows=1)\n",
        "        if len(df_test.columns) < 2:\n",
        "            print(\"âš ï¸  Dataset processado parece estar corrompido\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Erro ao verificar dataset processado: {e}\")\n",
        "        return False\n",
        "\n",
        "    print(\"âœ… Dataset processado encontrado e atualizado\")\n",
        "    return True\n",
        "\n",
        "# ================================================\n",
        "# 3. CARREGAR DATASET PROCESSADO\n",
        "# ================================================\n",
        "\n",
        "def load_processed_dataset():\n",
        "    \"\"\"Carrega o dataset jÃ¡ processado\"\"\"\n",
        "\n",
        "    print(\"ğŸ“Š Carregando dataset processado...\")\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(processed_csv_path)\n",
        "\n",
        "        # ValidaÃ§Ãµes bÃ¡sicas\n",
        "        required_columns = ['text', 'label']\n",
        "        if not all(col in data.columns for col in required_columns):\n",
        "            raise ValueError(f\"Colunas necessÃ¡rias nÃ£o encontradas: {required_columns}\")\n",
        "\n",
        "        # Verificar tipos de dados\n",
        "        if not pd.api.types.is_numeric_dtype(data['label']):\n",
        "            print(\"ğŸ”§ Convertendo coluna 'label' para numÃ©rico...\")\n",
        "            data['label'] = pd.to_numeric(data['label'], errors='coerce')\n",
        "            data = data.dropna(subset=['label'])\n",
        "            data['label'] = data['label'].astype(int)\n",
        "\n",
        "        # Remover linhas vazias\n",
        "        initial_len = len(data)\n",
        "        data = data.dropna(subset=['text', 'label'])\n",
        "        data = data[data['text'].astype(str).str.strip() != '']\n",
        "\n",
        "        if len(data) < initial_len:\n",
        "            print(f\"ğŸ§¹ Removidas {initial_len - len(data)} linhas vazias/invÃ¡lidas\")\n",
        "\n",
        "        print(f\"âœ… Dataset carregado: {len(data):,} registros\")\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao carregar dataset processado: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================================================\n",
        "# 4. PROCESSAR DATASET ORIGINAL (FUNÃ‡Ã•ES EXISTENTES)\n",
        "# ================================================\n",
        "\n",
        "def detect_delimiter(file_path, sample_size=1024):\n",
        "    \"\"\"Detecta automaticamente o delimitador do arquivo CSV\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            sample = f.read(sample_size)\n",
        "    except UnicodeDecodeError:\n",
        "        with open(file_path, 'r', encoding='latin-1') as f:\n",
        "            sample = f.read(sample_size)\n",
        "\n",
        "    delimiters = [',', ';', '\\t', '|']\n",
        "    counts = {delim: sample.count(delim) for delim in delimiters}\n",
        "    best_delim = max(counts, key=counts.get)\n",
        "    return best_delim if counts[best_delim] > 0 else ','\n",
        "\n",
        "def process_csv_file(file_path):\n",
        "    \"\"\"Processa um arquivo CSV individual\"\"\"\n",
        "    try:\n",
        "        delimiter = detect_delimiter(file_path)\n",
        "\n",
        "        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "        df = None\n",
        "\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding)\n",
        "                break\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"NÃ£o foi possÃ­vel ler o arquivo com nenhum encoding\")\n",
        "\n",
        "        # Renomear colunas se necessÃ¡rio\n",
        "        if 'text;label' in df.columns:\n",
        "            df[['text', 'label']] = df['text;label'].str.split(';', n=1, expand=True)\n",
        "            df = df.drop(columns=['text;label'])\n",
        "\n",
        "        # Garantir que temos as colunas necessÃ¡rias\n",
        "        if 'text' not in df.columns or 'label' not in df.columns:\n",
        "            text_cols = [col for col in df.columns if any(keyword in col.lower()\n",
        "                        for keyword in ['text', 'content', 'news', 'article', 'title'])]\n",
        "            label_cols = [col for col in df.columns if any(keyword in col.lower()\n",
        "                         for keyword in ['label', 'class', 'target', 'fake', 'real'])]\n",
        "\n",
        "            if text_cols and label_cols:\n",
        "                df = df.rename(columns={text_cols[0]: 'text', label_cols[0]: 'label'})\n",
        "            else:\n",
        "                if len(df.columns) == 1:\n",
        "                    col_name = df.columns[0]\n",
        "                    if ';' in str(df.iloc[0, 0]):\n",
        "                        df_split = df[col_name].str.split(';', expand=True)\n",
        "                        if df_split.shape[1] >= 2:\n",
        "                            df = df_split.rename(columns={0: 'text', 1: 'label'})\n",
        "\n",
        "        if 'text' not in df.columns or 'label' not in df.columns:\n",
        "            return None\n",
        "\n",
        "        # Processar rÃ³tulos\n",
        "        df['label'] = df['label'].astype(str).str.strip().str.lower()\n",
        "\n",
        "        label_mapping = {\n",
        "            'real': 1, 'true': 1, 'reliable': 1, 'legitimate': 1,\n",
        "            'fake': 0, 'false': 0, 'unreliable': 0, 'illegitimate': 0,\n",
        "            'verdadeiro': 1, 'verdadeira': 1, 'confiÃ¡vel': 1,\n",
        "            'falso': 0, 'falsa': 0, 'nÃ£o confiÃ¡vel': 0,\n",
        "            '1': 1, '1.0': 1, '0': 0, '0.0': 0,\n",
        "            'yes': 1, 'no': 0, 'sim': 1, 'nÃ£o': 0, 'nao': 0\n",
        "        }\n",
        "\n",
        "        df['label'] = df['label'].map(label_mapping)\n",
        "        df = df.dropna(subset=['label'])\n",
        "        df['label'] = df['label'].astype(int)\n",
        "\n",
        "        # Limpeza de texto\n",
        "        df = df.dropna(subset=['text'])\n",
        "        df['text'] = df['text'].astype(str).str.strip()\n",
        "        df = df[df['text'] != '']\n",
        "        df = df[df['text'] != 'nan']\n",
        "\n",
        "        return df, delimiter\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ğŸš¨ Erro ao processar {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def find_zip_file():\n",
        "    \"\"\"Encontra o arquivo ZIP no diretÃ³rio do projeto\"\"\"\n",
        "    global drive_zip_path\n",
        "\n",
        "    # Verificar se arquivo ZIP padrÃ£o existe\n",
        "    if os.path.exists(drive_zip_path):\n",
        "        return drive_zip_path\n",
        "\n",
        "    print(f\"âŒ Arquivo ZIP padrÃ£o nÃ£o encontrado: {os.path.basename(drive_zip_path)}\")\n",
        "\n",
        "    # Buscar arquivos ZIP no diretÃ³rio\n",
        "    if os.path.exists(project_dir):\n",
        "        print(\"ğŸ” Procurando arquivos ZIP no diretÃ³rio...\")\n",
        "        zip_files = [f for f in os.listdir(project_dir) if f.lower().endswith('.zip')]\n",
        "\n",
        "        if zip_files:\n",
        "            # Usar o primeiro arquivo ZIP encontrado\n",
        "            new_zip_path = os.path.join(project_dir, zip_files[0])\n",
        "            print(f\"ğŸ’¡ Arquivo ZIP encontrado: {zip_files[0]}\")\n",
        "\n",
        "            # Atualizar variÃ¡vel global\n",
        "            drive_zip_path = new_zip_path\n",
        "            return drive_zip_path\n",
        "        else:\n",
        "            print(\"âŒ Nenhum arquivo ZIP encontrado no diretÃ³rio\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"âŒ DiretÃ³rio do projeto nÃ£o encontrado\")\n",
        "        return None\n",
        "\n",
        "def process_original_dataset():\n",
        "    \"\"\"Processa o dataset original do arquivo ZIP\"\"\"\n",
        "\n",
        "    print(\"ğŸ”„ Processando dataset original...\")\n",
        "\n",
        "    # Encontrar arquivo ZIP\n",
        "    zip_file_path = find_zip_file()\n",
        "    if not zip_file_path:\n",
        "        raise FileNotFoundError(\"Nenhum arquivo ZIP encontrado!\")\n",
        "\n",
        "    # Extrair arquivo ZIP\n",
        "    print(f\"ğŸ“¦ Extraindo arquivo ZIP: {os.path.basename(zip_file_path)}\")\n",
        "    try:\n",
        "        os.makedirs(extract_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "        print(f\"âœ… Arquivo extraÃ­do para: {extract_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao extrair arquivo: {e}\")\n",
        "        raise\n",
        "\n",
        "    # Encontrar arquivos CSV\n",
        "    csv_files_found = []\n",
        "    for root, dirs, files in os.walk(extract_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.csv'):\n",
        "                csv_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"ğŸ” Arquivos CSV encontrados: {len(csv_files_found)}\")\n",
        "\n",
        "    if not csv_files_found:\n",
        "        print(\"âŒ Nenhum arquivo CSV encontrado no ZIP\")\n",
        "        # Listar conteÃºdo do ZIP para debug\n",
        "        print(\"ğŸ“‹ ConteÃºdo extraÃ­do:\")\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            level = root.replace(extract_dir, '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f\"{indent}ğŸ“ {os.path.basename(root)}/\")\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files:\n",
        "                print(f\"{subindent}ğŸ“„ {file}\")\n",
        "        raise ValueError(\"Nenhum arquivo CSV encontrado!\")\n",
        "\n",
        "    # Processar arquivos CSV\n",
        "    all_dfs = []\n",
        "    processed_files = []\n",
        "\n",
        "    for file_path in csv_files_found:\n",
        "        print(f\"ğŸ“„ Processando: {os.path.basename(file_path)}\")\n",
        "\n",
        "        result = process_csv_file(file_path)\n",
        "\n",
        "        if result is not None:\n",
        "            df, delimiter = result\n",
        "            all_dfs.append(df)\n",
        "            processed_files.append(file_path)\n",
        "            print(f\"âœ… Processado: {os.path.basename(file_path)} | Registros: {len(df)}\")\n",
        "        else:\n",
        "            print(f\"âŒ Falha ao processar: {os.path.basename(file_path)}\")\n",
        "\n",
        "    if not all_dfs:\n",
        "        raise ValueError(\"Nenhum dataset vÃ¡lido foi processado!\")\n",
        "\n",
        "    # Combinar datasets\n",
        "    print(f\"ğŸ”— Combinando {len(all_dfs)} datasets...\")\n",
        "    data = pd.concat(all_dfs, ignore_index=True)\n",
        "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return data, processed_files\n",
        "\n",
        "def save_processed_dataset(data, processed_files):\n",
        "    \"\"\"Salva o dataset processado e metadados\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Salvar dataset\n",
        "        data.to_csv(processed_csv_path, index=False, encoding='utf-8')\n",
        "        print(f\"ğŸ’¾ Dataset salvo em: {os.path.basename(processed_csv_path)}\")\n",
        "\n",
        "        # Salvar metadados\n",
        "        metadata = {\n",
        "            'processed_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'total_records': len(data),\n",
        "            'processed_files': len(processed_files),\n",
        "            'label_distribution': data['label'].value_counts().to_dict(),\n",
        "            'text_stats': {\n",
        "                'avg_length': float(data['text'].str.len().mean()),\n",
        "                'min_length': int(data['text'].str.len().min()),\n",
        "                'max_length': int(data['text'].str.len().max())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"FAKE NEWS DATASET - METADATA\\n\")\n",
        "            f.write(\"=\"*40 + \"\\n\")\n",
        "            for key, value in metadata.items():\n",
        "                f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "        print(f\"ğŸ“‹ Metadados salvos em: {os.path.basename(metadata_path)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Erro ao salvar arquivos: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 5. LÃ“GICA PRINCIPAL COM CACHE\n",
        "# ================================================\n",
        "\n",
        "def load_dataset_with_cache():\n",
        "    \"\"\"Carrega dataset usando cache inteligente\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ§  SISTEMA DE CACHE INTELIGENTE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Verificar se dataset processado existe e estÃ¡ atualizado\n",
        "    if check_processed_dataset():\n",
        "        print(\"âš¡ Usando dataset em cache...\")\n",
        "\n",
        "        data = load_processed_dataset()\n",
        "\n",
        "        if data is not None:\n",
        "            print(\"âœ… Dataset carregado do cache com sucesso!\")\n",
        "            return data, True  # True indica que foi carregado do cache\n",
        "        else:\n",
        "            print(\"âŒ Falha ao carregar do cache, processando novamente...\")\n",
        "\n",
        "    # Se chegou aqui, precisa processar o dataset original\n",
        "    print(\"ğŸ”„ Processando dataset original...\")\n",
        "\n",
        "    try:\n",
        "        data, processed_files = process_original_dataset()\n",
        "\n",
        "        # Salvar dataset processado para uso futuro\n",
        "        save_processed_dataset(data, processed_files)\n",
        "\n",
        "        print(\"âœ… Dataset processado e salvo com sucesso!\")\n",
        "        return data, False  # False indica que foi processado agora\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro no processamento: {e}\")\n",
        "        raise\n",
        "\n",
        "# ================================================\n",
        "# 6. EXECUTAR CARREGAMENTO\n",
        "# ================================================\n",
        "\n",
        "try:\n",
        "    # Carregar dataset\n",
        "    data, from_cache = load_dataset_with_cache()\n",
        "\n",
        "    # ================================================\n",
        "    # 7. EXIBIR RESULTADOS\n",
        "    # ================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“Š DATASET CARREGADO COM SUCESSO!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Indicar fonte dos dados\n",
        "    source_info = \"ğŸ’¾ CACHE\" if from_cache else \"ğŸ”„ PROCESSAMENTO ORIGINAL\"\n",
        "    print(f\"ğŸ“ Fonte: {source_info}\")\n",
        "\n",
        "    # EstatÃ­sticas do dataset\n",
        "    print(f\"ğŸ“Š EstatÃ­sticas:\")\n",
        "    print(f\"   - Total de registros: {len(data):,}\")\n",
        "\n",
        "    label_counts = data['label'].value_counts().sort_index()\n",
        "    for label, count in label_counts.items():\n",
        "        label_name = \"Real\" if label == 1 else \"Fake\"\n",
        "        percentage = (count / len(data)) * 100\n",
        "        print(f\"   - {label} ({label_name}): {count:,} registros ({percentage:.1f}%)\")\n",
        "\n",
        "    print(f\"   - Comprimento mÃ©dio do texto: {data['text'].str.len().mean():.1f} caracteres\")\n",
        "\n",
        "    # Mostrar informaÃ§Ãµes de cache\n",
        "    if from_cache:\n",
        "        print(f\"\\nâš¡ Vantagens do cache:\")\n",
        "        print(f\"   - Carregamento instantÃ¢neo\")\n",
        "        print(f\"   - Sem necessidade de reprocessamento\")\n",
        "        print(f\"   - Dados jÃ¡ limpos e validados\")\n",
        "    else:\n",
        "        print(f\"\\nğŸ”„ Dataset processado e salvo:\")\n",
        "        print(f\"   - PrÃ³xima execuÃ§Ã£o serÃ¡ mais rÃ¡pida\")\n",
        "        print(f\"   - Cache criado automaticamente\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # ================================================\n",
        "    # 8. EXEMPLOS DOS DADOS\n",
        "    # ================================================\n",
        "\n",
        "    print(\"\\nğŸ“‹ Exemplos dos dados:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for label in [0, 1]:\n",
        "        label_name = \"FAKE NEWS\" if label == 0 else \"REAL NEWS\"\n",
        "        sample = data[data['label'] == label].sample(n=1, random_state=42)\n",
        "\n",
        "        print(f\"\\nğŸ·ï¸  {label_name}:\")\n",
        "        for idx, row in sample.iterrows():\n",
        "            text_preview = row['text'][:200] + \"...\" if len(row['text']) > 200 else row['text']\n",
        "            print(f\"   ğŸ“„ {text_preview}\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"ğŸ‰ Dataset pronto para uso! VariÃ¡vel 'data' contÃ©m {len(data):,} registros\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ ERRO CRÃTICO: {e}\")\n",
        "    print(\"ğŸ’¡ Verifique se:\")\n",
        "    print(\"   - O Google Drive estÃ¡ montado corretamente\")\n",
        "    print(\"   - O arquivo ZIP existe no diretÃ³rio do projeto\")\n",
        "    print(\"   - VocÃª tem permissÃµes de leitura/escrita\")\n",
        "\n",
        "# ================================================\n",
        "# 9. FUNÃ‡ÃƒO PARA FORÃ‡AR REPROCESSAMENTO (OPCIONAL)\n",
        "# ================================================\n",
        "\n",
        "def force_reprocess():\n",
        "    \"\"\"ForÃ§a o reprocessamento do dataset, ignorando cache\"\"\"\n",
        "\n",
        "    print(\"ğŸ”„ ForÃ§ando reprocessamento...\")\n",
        "\n",
        "    # Remover arquivos de cache\n",
        "    files_to_remove = [processed_csv_path, metadata_path]\n",
        "\n",
        "    for file_path in files_to_remove:\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"ğŸ—‘ï¸  Removido: {os.path.basename(file_path)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸  Erro ao remover {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "    # Reprocessar\n",
        "    return load_dataset_with_cache()\n",
        "\n",
        "# Para forÃ§ar reprocessamento, descomente a linha abaixo:\n",
        "# data, from_cache = force_reprocess()\n",
        "\n",
        "print(f\"\\nğŸ’¡ Para forÃ§ar reprocessamento, execute: data, from_cache = force_reprocess()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK8WhsxlOpma"
      },
      "source": [
        "3. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k06zUuc9OrwL",
        "outputId": "a1e18e22-bc24-4b1e-ec7c-d9b0035c5c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#used for data cleaning\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  #removes punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  #removes numbers\n",
        "    text = text.lower()  #turns everything to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words]) #gets rid of stop words\n",
        "    return text\n",
        "\n",
        "data['text'] = data['text'].apply(clean_text) #applies changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2jHlEQUrv6_"
      },
      "source": [
        "3. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OoOa28EWz-R_"
      },
      "outputs": [],
      "source": [
        "#some train test splitting, 20%\n",
        "X = data['text']\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=142857)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMRvnHky0Adv"
      },
      "source": [
        "# 4. Bag of Words + Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5q8KDaoa0BX3"
      },
      "outputs": [],
      "source": [
        "bow = CountVectorizer(max_features=5000)\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_test_bow = bow.transform(X_test)\n",
        "bow_model = MultinomialNB()\n",
        "bow_model.fit(X_train_bow, y_train)\n",
        "y_pred_bow = bow_model.predict(X_test_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZoT9Drc0GPP"
      },
      "source": [
        "5. TF-IDF + Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uqdn0Hwl0Jmf"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "tfidf_model = LogisticRegression(max_iter=1000)\n",
        "tfidf_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_tfidf = tfidf_model.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryyJG0ZeQwYt",
        "outputId": "e8996f2b-ba2e-445d-ac80-2aa2050fb638",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Carrega o modelo com vetores prÃ©-treinados (~100MB, mais leve que Word2Vec do Google)\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qgmwu2O0NiY"
      },
      "source": [
        "6. Word2Vec + Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aCH68lwh0RRX"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Carrega o modelo com embeddings prÃ©-treinados (~100MB)\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# FunÃ§Ã£o para vetorizar textos com spaCy\n",
        "def vectorize_spacy(texts):\n",
        "    vectors = []\n",
        "    for doc in nlp.pipe(texts, disable=[\"ner\", \"parser\"]):\n",
        "        vectors.append(doc.vector)\n",
        "    return np.array(vectors)\n",
        "\n",
        "# VetorizaÃ§Ã£o dos conjuntos de treino e teste\n",
        "X_train_w2v = vectorize_spacy(X_train)\n",
        "X_test_w2v = vectorize_spacy(X_test)\n",
        "\n",
        "# Classificador com Random Forest\n",
        "w2v_model_clf = RandomForestClassifier()\n",
        "w2v_model_clf.fit(X_train_w2v, y_train)\n",
        "y_pred_w2v = w2v_model_clf.predict(X_test_w2v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG7JbInm0SII"
      },
      "source": [
        "# 7. GloVe + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U2yl0rmg0UuA"
      },
      "outputs": [],
      "source": [
        "# Simulando GloVe com Word2Vec para simplificar, mas pode-se usar GloVe real\n",
        "X_train_glove = X_train_w2v\n",
        "X_test_glove = X_test_w2v\n",
        "glove_model = XGBClassifier(eval_metric='logloss')\n",
        "glove_model.fit(X_train_glove, y_train)\n",
        "y_pred_glove = glove_model.predict(X_test_glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8SMUns20VVA"
      },
      "source": [
        "8. BERT + Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "69216df7ecf44c0ba878a93c1530ebcf",
            "a00c936f5c2440a1bf6eb8860a29d9c9",
            "0ad01008b409438da136de0eeaa8378f",
            "95a363294aa64993b28471a614da97ef",
            "b904633988434cb782b8c2fc4d31b870",
            "dafa6dcb99d546eeb7e6008cbbaa9f8a",
            "b68305c0b4794aacacec797abec699d9",
            "23a7892dda95456d860da010511e36b4",
            "f240cd219d1a4540ad7c7b9379253cbe",
            "6208cd3114384e9ebc27e9e107ffd429",
            "8017d3670bb24ce1a13535be5a632ab6",
            "f24f2f5aa11f4287aa6fd9e00e88dac5",
            "ae8536e81bc24759ad1067a80be3937b",
            "b1f8c37fe40946c0ad3d5a30beba9986",
            "7dd05fa3eb2044498840326170541925",
            "e177e5212d08444eabbd23d778463879",
            "38bd088993d24bf4a7ff6c03eecc8e27",
            "ec85cc8ec3314b0ba21286ea017e6a62",
            "9f386e360b30494ea04a38e036e0fc05",
            "11d793e01e744d2ab230bf3ecb882dee",
            "1dffa3931cd540e8aae943de6d1fc475",
            "3775c470eb2b477191ecaa65a855f0ba",
            "a057d9f84b6d4aeca91000746b39c668",
            "94711dceb9484598a2c361321fd57809",
            "8532749ce1dd4a3e906e513142b58866",
            "1fdbf2e6b1ba459f8e9b410403c3652c",
            "3587ed801fb944548898f6f9d06a9bde",
            "b26e0d239cf54b149e8b5bd769b47b6a",
            "8ac7cccdbb81406783e1bebdec27739a",
            "c1196076846e4c42b9921c01c5ed0a50",
            "aa87ecd7bd884036a71cb15235f713d4",
            "e641e50708334cb6ada8348a9c781260",
            "e638c9acf88a469c8ddbbe982be926f2",
            "ac98e4066b5d4a06a5ce45d86b6b01e4",
            "b0f6ae52d67448adab9e630c5e61ab48",
            "0753e3136ce84c10a5669f792cb6fece",
            "e3bc6f9dc542445bb40ac8524ad84ef2",
            "1e5897fb55bb4b9b9e734c643ca4a91a",
            "fb99e3d93ba34c85a67bd5b317ee2842",
            "1eec6b08fe5040d88f8f470ac899677f",
            "b44390415c3946cfa19835389a6d1e8d",
            "40b162589d41435cad0a6c23a60d59ef",
            "864adc25079145fc8facaba484ec4bc3",
            "b9afe98c956140b2bc0bd0d6b4d6dddc",
            "395f34276a3d4bf18badf99ab98e3d42",
            "95e14e4902e64c109f3f6324e0e8cc90",
            "ff7d62c0d56446d686dca272d411dd8c",
            "142255d417d64fefb6a81aaa22f19412",
            "d4b53be33fce4648a78ea937ab4e7513",
            "a8cbc107e90d4644bcd8f9bcb7f16cac",
            "d1d0f3978a424b92afb85b42effc63ba",
            "e62a380a40d0493684fc5fa625933253",
            "2f9058f327a040118404ea765474b5ae",
            "07d438e0833f40a99690aa0628fb2f2a",
            "72b5258f2d024e0a9d3d12c4d4f78bcf"
          ]
        },
        "id": "xVcufBzU0acg",
        "outputId": "29b59231-612d-4430-b40d-929f0d6667c3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69216df7ecf44c0ba878a93c1530ebcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24f2f5aa11f4287aa6fd9e00e88dac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a057d9f84b6d4aeca91000746b39c668"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac98e4066b5d4a06a5ce45d86b6b01e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "395f34276a3d4bf18badf99ab98e3d42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mffcs\u001b[0m (\u001b[33mffcs-cin-ufpe\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto/wandb/run-20250616_154117-906hlhua</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ffcs-cin-ufpe/huggingface/runs/906hlhua' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/ffcs-cin-ufpe/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ffcs-cin-ufpe/huggingface' target=\"_blank\">https://wandb.ai/ffcs-cin-ufpe/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ffcs-cin-ufpe/huggingface/runs/906hlhua' target=\"_blank\">https://wandb.ai/ffcs-cin-ufpe/huggingface/runs/906hlhua</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=max_len)\n",
        "        self.labels = list(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "train_dataset = FakeNewsDataset(X_train[:2000], y_train[:2000], tokenizer)\n",
        "test_dataset = FakeNewsDataset(X_test[:500], y_test[:500], tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./results\", per_device_train_batch_size=8, per_device_eval_batch_size=8, num_train_epochs=2, logging_dir=\"./logs\", logging_steps=10)\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset)\n",
        "trainer.train()\n",
        "preds = trainer.predict(test_dataset)\n",
        "y_pred_bert = np.argmax(preds.predictions, axis=1)\n",
        "y_true_bert = y_test[:500].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcf5UvSa0by4"
      },
      "source": [
        "# 9. Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khFMjdmV0eKx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate(name, y_true, y_pred):\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
        "    print(\"F1-score:\", f1_score(y_true, y_pred))\n",
        "\n",
        "evaluate(\"Bag of Words + NB\", y_test, y_pred_bow)\n",
        "evaluate(\"TF-IDF + LR\", y_test, y_pred_tfidf)\n",
        "evaluate(\"Word2Vec + RF\", y_test, y_pred_w2v)\n",
        "evaluate(\"GloVe + XGBoost\", y_test, y_pred_glove)\n",
        "evaluate(\"BERT\", y_true_bert, y_pred_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaY2808-9dQB"
      },
      "source": [
        "10. Matriz de confusao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLQeyG_I9gVJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# FunÃ§Ã£o para plotar a matriz de confusÃ£o\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['Fake', 'True'],\n",
        "                yticklabels=['Fake', 'True'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Matriz de ConfusÃ£o - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "# Plotar as matrizes de confusÃ£o para cada modelo\n",
        "plot_confusion_matrix(y_test, y_pred_bow, 'BoW + NB')\n",
        "plot_confusion_matrix(y_test, y_pred_tfidf, 'TF-IDF + LR')\n",
        "plot_confusion_matrix(y_test, y_pred_w2v, 'Word2Vec + RF')\n",
        "plot_confusion_matrix(y_test, y_pred_glove, 'GloVe + XGB')\n",
        "plot_confusion_matrix(y_true_bert, y_pred_bert, 'BERT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Q2X_Hi989t"
      },
      "source": [
        "11. Gerando grÃ¡ficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7gh3iud-DEH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# FunÃ§Ã£o para plotar as mÃ©tricas dos modelos\n",
        "def plot_metrics(models, metrics):\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    x = range(len(models))\n",
        "    width = 0.2\n",
        "\n",
        "    for i, (metric_name, metric_values) in enumerate(metrics.items()):\n",
        "        ax.bar([pos + width * i for pos in x], metric_values, width, label=metric_name)\n",
        "\n",
        "    ax.set_xticks([pos + width for pos in x])\n",
        "    ax.set_xticklabels(models)\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Performance dos Modelos')\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.ylim(0, 1.1)\n",
        "    plt.show()\n",
        "\n",
        "# Dados dos modelos e mÃ©tricas\n",
        "models = ['BoW + NB', 'TF-IDF + LR', 'Word2Vec + RF', 'GloVe + XGB', 'BERT']\n",
        "metrics = {\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_bow),\n",
        "        accuracy_score(y_test, y_pred_tfidf),\n",
        "        accuracy_score(y_test, y_pred_w2v),\n",
        "        accuracy_score(y_test, y_pred_glove),\n",
        "        accuracy_score(y_true_bert, y_pred_bert)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred_bow),\n",
        "        precision_score(y_test, y_pred_tfidf),\n",
        "        precision_score(y_test, y_pred_w2v),\n",
        "        precision_score(y_test, y_pred_glove),\n",
        "        precision_score(y_true_bert, y_pred_bert)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred_bow),\n",
        "        recall_score(y_test, y_pred_tfidf),\n",
        "        recall_score(y_test, y_pred_w2v),\n",
        "        recall_score(y_test, y_pred_glove),\n",
        "        recall_score(y_true_bert, y_pred_bert)\n",
        "    ],\n",
        "    'F1-score': [\n",
        "        f1_score(y_test, y_pred_bow),\n",
        "        f1_score(y_test, y_pred_tfidf),\n",
        "        f1_score(y_test, y_pred_w2v),\n",
        "        f1_score(y_test, y_pred_glove),\n",
        "        f1_score(y_true_bert, y_pred_bert)\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Plotar as mÃ©tricas\n",
        "plot_metrics(models, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k00U8qzU9wxp"
      },
      "source": [
        "12. Otimizando os hiperparametros com Optuna para BoW + Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBxznWqGUZLt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# FunÃ§Ã£o de objetivo para o Naive Bayes\n",
        "def objective_nb(trial):\n",
        "    # HiperparÃ¢metros a serem otimizados\n",
        "    params = {\n",
        "        'alpha': trial.suggest_float('alpha', 0.01, 10.0, log=True),  # SuavizaÃ§Ã£o de Laplace\n",
        "        'fit_prior': trial.suggest_categorical('fit_prior', [True, False])  # Aprender priors\n",
        "    }\n",
        "\n",
        "    # Modelo e avaliaÃ§Ã£o com validaÃ§Ã£o cruzada\n",
        "    model = MultinomialNB(**params)\n",
        "    score = cross_val_score(model, X_train_bow, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "# Executar otimizaÃ§Ã£o\n",
        "study_nb = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_nb.optimize(objective_nb, n_trials=20, n_jobs=-1)\n",
        "\n",
        "# Melhores hiperparÃ¢metros\n",
        "print(\"Melhores parÃ¢metros para Naive Bayes:\", study_nb.best_params)\n",
        "optuna.visualization.plot_optimization_history(study_nb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA26rtNtU9lR"
      },
      "source": [
        "13. Otimizando o modelo TF-IDF com Regressao Logistica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI34yZrlVDsY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_lr(trial):\n",
        "    # HiperparÃ¢metros a serem otimizados\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "    }\n",
        "\n",
        "    # Modelo e avaliaÃ§Ã£o com validaÃ§Ã£o cruzada\n",
        "    model = LogisticRegression(**params, max_iter=100)\n",
        "    score = cross_val_score(model, X_train_tfidf, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "# OtimizaÃ§Ã£o\n",
        "study_lr = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_lr.optimize(objective_lr, n_trials=10, n_jobs=-1)\n",
        "\n",
        "# Melhores hiperparÃ¢metros\n",
        "print(\"Melhores parÃ¢metros para LR:\", study_lr.best_params)\n",
        "optuna.visualization.plot_optimization_history(study_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2GjNuvXVKW0"
      },
      "source": [
        "14. Otimizando o modelo Random Forest + Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJkdTh6pVRnG"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_rf(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train_w2v, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "study_rf = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_rf.optimize(objective_rf, n_trials=5, n_jobs=-1)\n",
        "optuna.visualization.plot_optimization_history(study_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TubF1bEpVYCF"
      },
      "source": [
        "15. Otimizando o modelo do XGBoost + GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9iz5_8QVdvF"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_xgb(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200)\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params, eval_metric='logloss')\n",
        "    score = cross_val_score(model, X_train_glove, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "study_xgb = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_xgb.optimize(objective_xgb, n_trials=10, n_jobs=-1)\n",
        "optuna.visualization.plot_optimization_history(study_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skSIsST1VtJm"
      },
      "source": [
        "16. Otimizando o modelo BERT + Fine-Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMnXVoKyVy3j"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_bert(trial):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        learning_rate=trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n",
        "        per_device_train_batch_size=trial.suggest_categorical('batch_size', [8, 16]),\n",
        "        num_train_epochs=trial.suggest_int('num_epochs', 1, 3),\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    results = trainer.evaluate()\n",
        "    return results['eval_loss']  # Minimizar a perda\n",
        "\n",
        "study_bert = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
        "study_bert.optimize(objective_bert, n_trials=5, n_jobs=-1)\n",
        "optuna.visualization.plot_optimization_history(study_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyYPNv8kaT0A"
      },
      "source": [
        "17. ExibiÃ§Ã£o das melhorias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZcDyXLvaWF_"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# 1. Naive Bayes (NB) - Melhores ParÃ¢metros\n",
        "# ================================================\n",
        "best_nb_params = study_nb.best_params\n",
        "best_nb_model = MultinomialNB(**best_nb_params)\n",
        "best_nb_model.fit(X_train_bow, y_train)\n",
        "y_pred_nb = best_nb_model.predict(X_test_bow)\n",
        "\n",
        "# AvaliaÃ§Ã£o\n",
        "print(\"=== Naive Bayes (Otimizado) ===\")\n",
        "print(\"AcurÃ¡cia:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_nb))\n",
        "\n",
        "# ================================================\n",
        "# 2. Logistic Regression (TF-IDF) - Melhores ParÃ¢metros\n",
        "# ================================================\n",
        "best_lr_params = study_lr.best_params\n",
        "best_lr_model = LogisticRegression(**best_lr_params, max_iter=100)\n",
        "best_lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = best_lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# AvaliaÃ§Ã£o\n",
        "print(\"=== Logistic Regression (Otimizado) ===\")\n",
        "print(\"AcurÃ¡cia:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_lr))\n",
        "\n",
        "# ================================================\n",
        "# 3. Random Forest (Word2Vec) - Melhores ParÃ¢metros\n",
        "# ================================================\n",
        "best_rf_params = study_rf.best_params\n",
        "best_rf_model = RandomForestClassifier(**best_rf_params)\n",
        "best_rf_model.fit(X_train_w2v, y_train)\n",
        "y_pred_rf = best_rf_model.predict(X_test_w2v)\n",
        "\n",
        "# AvaliaÃ§Ã£o\n",
        "print(\"\\\\n=== Random Forest (Otimizado) ===\")\n",
        "print(\"AcurÃ¡cia:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_rf))\n",
        "\n",
        "# ================================================\n",
        "# 4. XGBoost (GloVe) - Melhores ParÃ¢metros\n",
        "# ================================================\n",
        "best_xgb_params = study_xgb.best_params\n",
        "best_xgb_model = XGBClassifier(**best_xgb_params, eval_metric='logloss')\n",
        "best_xgb_model.fit(X_train_glove, y_train)\n",
        "y_pred_xgb = best_xgb_model.predict(X_test_glove)\n",
        "\n",
        "# AvaliaÃ§Ã£o\n",
        "print(\"\\\\n=== XGBoost (Otimizado) ===\")\n",
        "print(\"AcurÃ¡cia:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_xgb))\n",
        "\n",
        "# ================================================\n",
        "# 5. BERT (Fine-Tuning) - Melhores ParÃ¢metros\n",
        "# ================================================\n",
        "best_bert_params = study_bert.best_params\n",
        "\n",
        "# Configurar os argumentos de treino com os melhores parÃ¢metros\n",
        "best_training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=best_bert_params['learning_rate'],\n",
        "    per_device_train_batch_size=best_bert_params['batch_size'],\n",
        "    num_train_epochs=best_bert_params['num_epochs'],\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Treinar o modelo final com todos os dados (sem validaÃ§Ã£o cruzada)\n",
        "final_trainer = Trainer(\n",
        "    model=model,\n",
        "    args=best_training_args,\n",
        "    train_dataset=X_train,  # Use o dataset completo\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "final_trainer.train()\n",
        "\n",
        "# Fazer previsÃµes finais\n",
        "preds = final_trainer.predict(test_dataset)\n",
        "y_pred_bert = np.argmax(preds.predictions, axis=1)\n",
        "\n",
        "# AvaliaÃ§Ã£o\n",
        "print(\"\\\\n=== BERT (Otimizado) ===\")\n",
        "print(\"AcurÃ¡cia:\", accuracy_score(y_true_bert, y_pred_bert))\n",
        "print(\"F1-score:\", f1_score(y_true_bert, y_pred_bert))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicabilidade"
      ],
      "metadata": {
        "id": "5NwGOY_le26y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# EXPLICABILIDADE DOS MODELOS\n",
        "# ================================================\n",
        "\n",
        "import shap\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Configurar SHAP\n",
        "shap.initjs()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANÃLISE DE EXPLICABILIDADE DOS MODELOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ================================================\n",
        "# 1. PREPARAÃ‡ÃƒO DOS DADOS PARA EXPLICABILIDADE\n",
        "# ================================================\n",
        "\n",
        "# Selecionar algumas amostras para explicar\n",
        "n_samples_explain = 10\n",
        "sample_indices = np.random.choice(len(X_test), n_samples_explain, replace=False)\n",
        "sample_texts = [df_test.iloc[i]['text'] for i in sample_indices]  # Assumindo que vocÃª tem o texto original\n",
        "sample_labels = y_test.iloc[sample_indices] if hasattr(y_test, 'iloc') else y_test[sample_indices]\n",
        "\n",
        "print(f\"Analisando {n_samples_explain} amostras selecionadas aleatoriamente...\")\n",
        "\n",
        "# ================================================\n",
        "# 2. EXPLICABILIDADE COM SHAP\n",
        "# ================================================\n",
        "\n",
        "def explain_with_shap():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EXPLICABILIDADE COM SHAP\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 2.1 Logistic Regression (TF-IDF) - Linear Explainer\n",
        "    print(\"\\n--- Logistic Regression (TF-IDF) ---\")\n",
        "    try:\n",
        "        # Criar explainer para modelo linear\n",
        "        explainer_lr = shap.LinearExplainer(best_lr_model, X_train_tfidf)\n",
        "        shap_values_lr = explainer_lr.shap_values(X_test_tfidf[sample_indices])\n",
        "\n",
        "        # Obter nomes das features (palavras do vocabulÃ¡rio)\n",
        "        feature_names_tfidf = vectorizer_tfidf.get_feature_names_out()\n",
        "\n",
        "        # VisualizaÃ§Ã£o - Summary Plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values_lr, X_test_tfidf[sample_indices],\n",
        "                         feature_names=feature_names_tfidf, show=False, max_display=20)\n",
        "        plt.title(\"SHAP Summary Plot - Logistic Regression\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Waterfall plot para primeira amostra\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        shap.waterfall_plot(explainer_lr.expected_value, shap_values_lr[0],\n",
        "                           X_test_tfidf[sample_indices[0]], feature_names=feature_names_tfidf)\n",
        "        plt.title(f\"SHAP Waterfall Plot - Amostra 1 (Label: {sample_labels[0]})\")\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na explicabilidade LR: {e}\")\n",
        "\n",
        "    # 2.2 Random Forest (Word2Vec) - Tree Explainer\n",
        "    print(\"\\n--- Random Forest (Word2Vec) ---\")\n",
        "    try:\n",
        "        # Tree explainer para Random Forest\n",
        "        explainer_rf = shap.TreeExplainer(best_rf_model)\n",
        "        shap_values_rf = explainer_rf.shap_values(X_test_w2v[sample_indices])\n",
        "\n",
        "        # Se classificaÃ§Ã£o binÃ¡ria, pegar apenas uma classe\n",
        "        if len(shap_values_rf) == 2:\n",
        "            shap_values_rf = shap_values_rf[1]\n",
        "\n",
        "        # Summary plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values_rf, X_test_w2v[sample_indices], show=False, max_display=20)\n",
        "        plt.title(\"SHAP Summary Plot - Random Forest\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na explicabilidade RF: {e}\")\n",
        "\n",
        "    # 2.3 XGBoost (GloVe) - Tree Explainer\n",
        "    print(\"\\n--- XGBoost (GloVe) ---\")\n",
        "    try:\n",
        "        # Tree explainer para XGBoost\n",
        "        explainer_xgb = shap.TreeExplainer(best_xgb_model)\n",
        "        shap_values_xgb = explainer_xgb.shap_values(X_test_glove[sample_indices])\n",
        "\n",
        "        # Summary plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values_xgb, X_test_glove[sample_indices], show=False, max_display=20)\n",
        "        plt.title(\"SHAP Summary Plot - XGBoost\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Feature importance global\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values_xgb, X_test_glove[sample_indices],\n",
        "                         plot_type=\"bar\", show=False, max_display=15)\n",
        "        plt.title(\"SHAP Feature Importance - XGBoost\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na explicabilidade XGB: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 3. EXPLICABILIDADE COM LIME (COMPARAÃ‡ÃƒO)\n",
        "# ================================================\n",
        "\n",
        "def explain_with_lime():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EXPLICABILIDADE COM LIME (COMPARAÃ‡ÃƒO)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Criar explainer LIME para texto\n",
        "    explainer_lime = LimeTextExplainer(class_names=['Negativo', 'Positivo'])\n",
        "\n",
        "    # FunÃ§Ã£o de prediÃ§Ã£o para LIME (usando Logistic Regression)\n",
        "    def predict_proba_lr(texts):\n",
        "        # Transformar textos usando o mesmo pipeline\n",
        "        texts_tfidf = vectorizer_tfidf.transform(texts)\n",
        "        return best_lr_model.predict_proba(texts_tfidf)\n",
        "\n",
        "    # Explicar algumas amostras\n",
        "    print(\"\\n--- LIME Explanations (Logistic Regression) ---\")\n",
        "\n",
        "    for i in range(min(3, len(sample_texts))):  # Explicar apenas 3 amostras\n",
        "        try:\n",
        "            # Gerar explicaÃ§Ã£o\n",
        "            exp = explainer_lime.explain_instance(\n",
        "                sample_texts[i],\n",
        "                predict_proba_lr,\n",
        "                num_features=10,\n",
        "                num_samples=1000\n",
        "            )\n",
        "\n",
        "            # Mostrar explicaÃ§Ã£o\n",
        "            print(f\"\\nAmostra {i+1} (Label Real: {sample_labels[i]}):\")\n",
        "            print(\"Texto:\", sample_texts[i][:200] + \"...\" if len(sample_texts[i]) > 200 else sample_texts[i])\n",
        "            print(\"\\nPalavras mais importantes:\")\n",
        "            for word, importance in exp.as_list():\n",
        "                print(f\"  {word}: {importance:.4f}\")\n",
        "\n",
        "            # VisualizaÃ§Ã£o HTML (opcional)\n",
        "            exp.save_to_file(f'lime_explanation_sample_{i+1}.html')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na explicaÃ§Ã£o LIME para amostra {i+1}: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 4. ANÃLISE COMPARATIVA DE FEATURES IMPORTANTES\n",
        "# ================================================\n",
        "\n",
        "def analyze_important_features():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ANÃLISE DE FEATURES IMPORTANTES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 4.1 Features importantes do Logistic Regression\n",
        "    print(\"\\n--- Top Features - Logistic Regression ---\")\n",
        "    feature_names = vectorizer_tfidf.get_feature_names_out()\n",
        "    coefficients = best_lr_model.coef_[0]\n",
        "\n",
        "    # Top features positivas e negativas\n",
        "    top_positive = np.argsort(coefficients)[-15:][::-1]\n",
        "    top_negative = np.argsort(coefficients)[:15]\n",
        "\n",
        "    print(\"Top 15 palavras para classe POSITIVA:\")\n",
        "    for idx in top_positive:\n",
        "        print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "    print(\"\\nTop 15 palavras para classe NEGATIVA:\")\n",
        "    for idx in top_negative:\n",
        "        print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "    # 4.2 Feature importance do Random Forest\n",
        "    print(\"\\n--- Feature Importance - Random Forest ---\")\n",
        "    rf_importance = best_rf_model.feature_importances_\n",
        "    top_rf_features = np.argsort(rf_importance)[-15:][::-1]\n",
        "\n",
        "    print(\"Top 15 dimensÃµes mais importantes (Word2Vec):\")\n",
        "    for i, idx in enumerate(top_rf_features):\n",
        "        print(f\"  DimensÃ£o {idx}: {rf_importance[idx]:.4f}\")\n",
        "\n",
        "    # 4.3 Feature importance do XGBoost\n",
        "    print(\"\\n--- Feature Importance - XGBoost ---\")\n",
        "    xgb_importance = best_xgb_model.feature_importances_\n",
        "    top_xgb_features = np.argsort(xgb_importance)[-15:][::-1]\n",
        "\n",
        "    print(\"Top 15 dimensÃµes mais importantes (GloVe):\")\n",
        "    for i, idx in enumerate(top_xgb_features):\n",
        "        print(f\"  DimensÃ£o {idx}: {xgb_importance[idx]:.4f}\")\n",
        "\n",
        "# ================================================\n",
        "# 5. VISUALIZAÃ‡Ã•ES AVANÃ‡ADAS\n",
        "# ================================================\n",
        "\n",
        "def create_advanced_visualizations():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"VISUALIZAÃ‡Ã•ES AVANÃ‡ADAS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 5.1 WordCloud das palavras mais importantes\n",
        "    try:\n",
        "        feature_names = vectorizer_tfidf.get_feature_names_out()\n",
        "        coefficients = best_lr_model.coef_[0]\n",
        "\n",
        "        # Criar dicionÃ¡rio para WordCloud\n",
        "        word_importance = {}\n",
        "        top_indices = np.argsort(np.abs(coefficients))[-100:]  # Top 100 palavras\n",
        "\n",
        "        for idx in top_indices:\n",
        "            word_importance[feature_names[idx]] = abs(coefficients[idx])\n",
        "\n",
        "        # Gerar WordCloud\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # WordCloud para palavras positivas\n",
        "        plt.subplot(1, 2, 1)\n",
        "        positive_words = {word: coef for word, coef in word_importance.items()\n",
        "                         if coefficients[np.where(feature_names == word)[0][0]] > 0}\n",
        "        if positive_words:\n",
        "            wc_pos = WordCloud(width=600, height=400, background_color='white').generate_from_frequencies(positive_words)\n",
        "            plt.imshow(wc_pos, interpolation='bilinear')\n",
        "            plt.title('Palavras Importantes - Sentimento POSITIVO')\n",
        "            plt.axis('off')\n",
        "\n",
        "        # WordCloud para palavras negativas\n",
        "        plt.subplot(1, 2, 2)\n",
        "        negative_words = {word: coef for word, coef in word_importance.items()\n",
        "                         if coefficients[np.where(feature_names == word)[0][0]] < 0}\n",
        "        if negative_words:\n",
        "            wc_neg = WordCloud(width=600, height=400, background_color='white').generate_from_frequencies(negative_words)\n",
        "            plt.imshow(wc_neg, interpolation='bilinear')\n",
        "            plt.title('Palavras Importantes - Sentimento NEGATIVO')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na criaÃ§Ã£o do WordCloud: {e}\")\n",
        "\n",
        "    # 5.2 ComparaÃ§Ã£o de importÃ¢ncia entre modelos\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Normalizar importÃ¢ncias para comparaÃ§Ã£o\n",
        "        lr_importance_norm = np.abs(coefficients) / np.max(np.abs(coefficients))\n",
        "        rf_importance_norm = rf_importance / np.max(rf_importance)\n",
        "        xgb_importance_norm = xgb_importance / np.max(xgb_importance)\n",
        "\n",
        "        # Plotar distribuiÃ§Ãµes\n",
        "        plt.hist(lr_importance_norm, bins=50, alpha=0.7, label='Logistic Regression', density=True)\n",
        "        plt.hist(rf_importance_norm, bins=50, alpha=0.7, label='Random Forest', density=True)\n",
        "        plt.hist(xgb_importance_norm, bins=50, alpha=0.7, label='XGBoost', density=True)\n",
        "\n",
        "        plt.xlabel('ImportÃ¢ncia Normalizada')\n",
        "        plt.ylabel('Densidade')\n",
        "        plt.title('DistribuiÃ§Ã£o de ImportÃ¢ncia das Features por Modelo')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na comparaÃ§Ã£o de importÃ¢ncias: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 6. EXECUTAR ANÃLISES\n",
        "# ================================================\n",
        "\n",
        "def run_explainability_analysis():\n",
        "    \"\"\"Executar toda a anÃ¡lise de explicabilidade\"\"\"\n",
        "\n",
        "    print(\"Iniciando anÃ¡lise de explicabilidade...\")\n",
        "\n",
        "    # Executar SHAP\n",
        "    explain_with_shap()\n",
        "\n",
        "    # Executar LIME (comparaÃ§Ã£o)\n",
        "    explain_with_lime()\n",
        "\n",
        "    # Analisar features importantes\n",
        "    analyze_important_features()\n",
        "\n",
        "    # Criar visualizaÃ§Ãµes avanÃ§adas\n",
        "    create_advanced_visualizations()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESUMO DA ANÃLISE DE EXPLICABILIDADE\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\"\"\n",
        "    âœ… SHAP Analysis:\n",
        "       - Fornece explicaÃ§Ãµes baseadas em valores Shapley\n",
        "       - Mostra contribuiÃ§Ã£o de cada feature para prediÃ§Ãµes individuais\n",
        "       - Permite comparaÃ§Ã£o entre diferentes modelos\n",
        "\n",
        "    âœ… LIME Analysis:\n",
        "       - Oferece explicaÃ§Ãµes locais interpretÃ¡veis\n",
        "       - Ãštil para entender prediÃ§Ãµes especÃ­ficas\n",
        "       - Funciona bem com dados de texto\n",
        "\n",
        "    âœ… Feature Importance:\n",
        "       - Identifica palavras/dimensÃµes mais relevantes\n",
        "       - Compara importÃ¢ncia entre diferentes representaÃ§Ãµes\n",
        "       - Ajuda na interpretaÃ§Ã£o do modelo\n",
        "\n",
        "    ğŸ’¡ RecomendaÃ§Ã£o: Use SHAP para anÃ¡lise geral e LIME para casos especÃ­ficos\n",
        "    \"\"\")\n",
        "\n",
        "# Executar a anÃ¡lise completa\n",
        "if __name__ == \"__main__\":\n",
        "    run_explainability_analysis()"
      ],
      "metadata": {
        "id": "rdVbzMVEMnal"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69216df7ecf44c0ba878a93c1530ebcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a00c936f5c2440a1bf6eb8860a29d9c9",
              "IPY_MODEL_0ad01008b409438da136de0eeaa8378f",
              "IPY_MODEL_95a363294aa64993b28471a614da97ef"
            ],
            "layout": "IPY_MODEL_b904633988434cb782b8c2fc4d31b870"
          }
        },
        "a00c936f5c2440a1bf6eb8860a29d9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafa6dcb99d546eeb7e6008cbbaa9f8a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b68305c0b4794aacacec797abec699d9",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "0ad01008b409438da136de0eeaa8378f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a7892dda95456d860da010511e36b4",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f240cd219d1a4540ad7c7b9379253cbe",
            "value": 48
          }
        },
        "95a363294aa64993b28471a614da97ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6208cd3114384e9ebc27e9e107ffd429",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8017d3670bb24ce1a13535be5a632ab6",
            "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡3.52kB/s]"
          }
        },
        "b904633988434cb782b8c2fc4d31b870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafa6dcb99d546eeb7e6008cbbaa9f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68305c0b4794aacacec797abec699d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a7892dda95456d860da010511e36b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f240cd219d1a4540ad7c7b9379253cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6208cd3114384e9ebc27e9e107ffd429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8017d3670bb24ce1a13535be5a632ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24f2f5aa11f4287aa6fd9e00e88dac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae8536e81bc24759ad1067a80be3937b",
              "IPY_MODEL_b1f8c37fe40946c0ad3d5a30beba9986",
              "IPY_MODEL_7dd05fa3eb2044498840326170541925"
            ],
            "layout": "IPY_MODEL_e177e5212d08444eabbd23d778463879"
          }
        },
        "ae8536e81bc24759ad1067a80be3937b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38bd088993d24bf4a7ff6c03eecc8e27",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ec85cc8ec3314b0ba21286ea017e6a62",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "b1f8c37fe40946c0ad3d5a30beba9986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f386e360b30494ea04a38e036e0fc05",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11d793e01e744d2ab230bf3ecb882dee",
            "value": 231508
          }
        },
        "7dd05fa3eb2044498840326170541925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dffa3931cd540e8aae943de6d1fc475",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3775c470eb2b477191ecaa65a855f0ba",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡4.36MB/s]"
          }
        },
        "e177e5212d08444eabbd23d778463879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38bd088993d24bf4a7ff6c03eecc8e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec85cc8ec3314b0ba21286ea017e6a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f386e360b30494ea04a38e036e0fc05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d793e01e744d2ab230bf3ecb882dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dffa3931cd540e8aae943de6d1fc475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3775c470eb2b477191ecaa65a855f0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a057d9f84b6d4aeca91000746b39c668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94711dceb9484598a2c361321fd57809",
              "IPY_MODEL_8532749ce1dd4a3e906e513142b58866",
              "IPY_MODEL_1fdbf2e6b1ba459f8e9b410403c3652c"
            ],
            "layout": "IPY_MODEL_3587ed801fb944548898f6f9d06a9bde"
          }
        },
        "94711dceb9484598a2c361321fd57809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26e0d239cf54b149e8b5bd769b47b6a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8ac7cccdbb81406783e1bebdec27739a",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "8532749ce1dd4a3e906e513142b58866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1196076846e4c42b9921c01c5ed0a50",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa87ecd7bd884036a71cb15235f713d4",
            "value": 466062
          }
        },
        "1fdbf2e6b1ba459f8e9b410403c3652c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e641e50708334cb6ada8348a9c781260",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e638c9acf88a469c8ddbbe982be926f2",
            "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡11.0MB/s]"
          }
        },
        "3587ed801fb944548898f6f9d06a9bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26e0d239cf54b149e8b5bd769b47b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac7cccdbb81406783e1bebdec27739a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1196076846e4c42b9921c01c5ed0a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa87ecd7bd884036a71cb15235f713d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e641e50708334cb6ada8348a9c781260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e638c9acf88a469c8ddbbe982be926f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac98e4066b5d4a06a5ce45d86b6b01e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0f6ae52d67448adab9e630c5e61ab48",
              "IPY_MODEL_0753e3136ce84c10a5669f792cb6fece",
              "IPY_MODEL_e3bc6f9dc542445bb40ac8524ad84ef2"
            ],
            "layout": "IPY_MODEL_1e5897fb55bb4b9b9e734c643ca4a91a"
          }
        },
        "b0f6ae52d67448adab9e630c5e61ab48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb99e3d93ba34c85a67bd5b317ee2842",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1eec6b08fe5040d88f8f470ac899677f",
            "value": "config.json:â€‡100%"
          }
        },
        "0753e3136ce84c10a5669f792cb6fece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44390415c3946cfa19835389a6d1e8d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b162589d41435cad0a6c23a60d59ef",
            "value": 570
          }
        },
        "e3bc6f9dc542445bb40ac8524ad84ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864adc25079145fc8facaba484ec4bc3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9afe98c956140b2bc0bd0d6b4d6dddc",
            "value": "â€‡570/570â€‡[00:00&lt;00:00,â€‡32.4kB/s]"
          }
        },
        "1e5897fb55bb4b9b9e734c643ca4a91a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb99e3d93ba34c85a67bd5b317ee2842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eec6b08fe5040d88f8f470ac899677f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44390415c3946cfa19835389a6d1e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b162589d41435cad0a6c23a60d59ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "864adc25079145fc8facaba484ec4bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9afe98c956140b2bc0bd0d6b4d6dddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "395f34276a3d4bf18badf99ab98e3d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95e14e4902e64c109f3f6324e0e8cc90",
              "IPY_MODEL_ff7d62c0d56446d686dca272d411dd8c",
              "IPY_MODEL_142255d417d64fefb6a81aaa22f19412"
            ],
            "layout": "IPY_MODEL_d4b53be33fce4648a78ea937ab4e7513"
          }
        },
        "95e14e4902e64c109f3f6324e0e8cc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8cbc107e90d4644bcd8f9bcb7f16cac",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d1d0f3978a424b92afb85b42effc63ba",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "ff7d62c0d56446d686dca272d411dd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62a380a40d0493684fc5fa625933253",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f9058f327a040118404ea765474b5ae",
            "value": 440449768
          }
        },
        "142255d417d64fefb6a81aaa22f19412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d438e0833f40a99690aa0628fb2f2a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_72b5258f2d024e0a9d3d12c4d4f78bcf",
            "value": "â€‡440M/440Mâ€‡[00:16&lt;00:00,â€‡21.6MB/s]"
          }
        },
        "d4b53be33fce4648a78ea937ab4e7513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cbc107e90d4644bcd8f9bcb7f16cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d0f3978a424b92afb85b42effc63ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e62a380a40d0493684fc5fa625933253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f9058f327a040118404ea765474b5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07d438e0833f40a99690aa0628fb2f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b5258f2d024e0a9d3d12c4d4f78bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}