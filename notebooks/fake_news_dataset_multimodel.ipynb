{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWnpmRWVumhd"
      },
      "source": [
        "0. Instalando pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YKrOmWIEutGN",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e86d8f-9d9e-49b5-de84-9e52fb3c738a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ torch: 2.6.0+cu124 → 2.3.0\n",
            "❌ transformers: 4.52.4 → 4.51.3\n",
            "✅ peft: 0.15.2\n",
            "❌ sentence-transformers: 4.1.0 → 2.5.1\n",
            "\n",
            "🔄 Reinstalando 3 pacote(s)...\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Successfully uninstalled transformers-4.52.4\n",
            "Found existing installation: sentence-transformers 4.1.0\n",
            "Uninstalling sentence-transformers-4.1.0:\n",
            "  Successfully uninstalled sentence-transformers-4.1.0\n",
            "Collecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.18.0\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchaudio==2.3.0\n",
            "  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.2.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.15.2 requires transformers, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 triton-2.3.0\n",
            "Collecting transformers==4.51.3\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2025.4.26)\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "Successfully installed transformers-4.51.3\n",
            "Collecting sentence-transformers==2.5.1\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.5.1) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (1.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.5.1) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers==2.5.1) (12.5.82)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers==2.5.1) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.5.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.5.1) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.5.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.5.1) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.11.0->sentence-transformers==2.5.1) (1.3.0)\n",
            "Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.5.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.2.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=3c3aec079985fe16e78e2a563e2c83d831cdbd021f0f572b46195edc81483ccd\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
            "Successfully built lime\n",
            "Installing collected packages: colorlog, alembic, optuna, lime\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 lime-0.2.0.1 optuna-4.4.0\n",
            "✅ Reinstalação concluída!\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# VERIFICAÇÃO INTELIGENTE DE PACOTES\n",
        "# ================================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def smart_package_check():\n",
        "    \"\"\"Verifica e instala apenas pacotes necessários\"\"\"\n",
        "\n",
        "    # Versões desejadas\n",
        "    target_versions = {\n",
        "        'torch': '2.3.0',\n",
        "        'transformers': '4.51.3',\n",
        "        'peft': '0.15.2',\n",
        "        'sentence-transformers': '2.5.1'\n",
        "    }\n",
        "\n",
        "    needs_reinstall = []\n",
        "\n",
        "    # Verificar cada pacote\n",
        "    for package, target_version in target_versions.items():\n",
        "        try:\n",
        "            result = subprocess.run([sys.executable, '-c',\n",
        "                f\"import {package.replace('-', '_')}; print({package.replace('-', '_')}.__version__)\"],\n",
        "                capture_output=True, text=True)\n",
        "\n",
        "            if result.returncode == 0:\n",
        "                current_version = result.stdout.strip()\n",
        "                if current_version != target_version:\n",
        "                    print(f\"❌ {package}: {current_version} → {target_version}\")\n",
        "                    needs_reinstall.append(package)\n",
        "                else:\n",
        "                    print(f\"✅ {package}: {current_version}\")\n",
        "            else:\n",
        "                print(f\"❌ {package}: não instalado\")\n",
        "                needs_reinstall.append(package)\n",
        "        except:\n",
        "            print(f\"❌ {package}: erro na verificação\")\n",
        "            needs_reinstall.append(package)\n",
        "\n",
        "    # Reinstalar apenas se necessário\n",
        "    if needs_reinstall:\n",
        "        print(f\"\\n🔄 Reinstalando {len(needs_reinstall)} pacote(s)...\")\n",
        "\n",
        "        # Desinstalar\n",
        "        !pip uninstall -y {' '.join(needs_reinstall)}\n",
        "\n",
        "        # Reinstalar com versões corretas\n",
        "        if 'torch' in needs_reinstall:\n",
        "            !pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0\n",
        "        if 'transformers' in needs_reinstall:\n",
        "            !pip install transformers==4.51.3\n",
        "        if 'peft' in needs_reinstall:\n",
        "            !pip install peft==0.15.2\n",
        "        if 'sentence-transformers' in needs_reinstall:\n",
        "            !pip install sentence-transformers==2.5.1\n",
        "\n",
        "        # Instalar pacotes adicionais\n",
        "        !pip install optuna shap lime wordcloud\n",
        "\n",
        "        print(\"✅ Reinstalação concluída!\")\n",
        "    else:\n",
        "        # Verificar pacotes adicionais\n",
        "        additional = ['optuna', 'shap', 'lime', 'wordcloud']\n",
        "        missing = []\n",
        "\n",
        "        for pkg in additional:\n",
        "            try:\n",
        "                __import__(pkg.replace('-', '_'))\n",
        "                print(f\"✅ {pkg}: instalado\")\n",
        "            except ImportError:\n",
        "                missing.append(pkg)\n",
        "\n",
        "        if missing:\n",
        "            print(f\"📦 Instalando pacotes adicionais: {missing}\")\n",
        "            !pip install {' '.join(missing)}\n",
        "        else:\n",
        "            print(\"🎉 Todos os pacotes já estão corretos!\")\n",
        "\n",
        "# Executar verificação\n",
        "smart_package_check()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importando pacotes"
      ],
      "metadata": {
        "id": "tQyi3HYIi0Q5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u65aY4nXrvHo"
      },
      "outputs": [],
      "source": [
        "# 1. Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WPlYWE1fupwV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoJCP_OXr2R3"
      },
      "source": [
        "# 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# MONTAR GOOGLE DRIVE CORRETAMENTE\n",
        "# ================================================\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Montar o Google Drive na raiz\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Definir o caminho para seu projeto\n",
        "project_path = '/content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto'\n",
        "\n",
        "# 3. Verificar se o diretório existe\n",
        "if os.path.exists(project_path):\n",
        "    print(f\"✅ Diretório encontrado: {project_path}\")\n",
        "\n",
        "    # Navegar para o diretório do projeto\n",
        "    os.chdir(project_path)\n",
        "    print(f\"📁 Diretório atual: {os.getcwd()}\")\n",
        "\n",
        "    # Listar arquivos no diretório\n",
        "    print(\"\\n📋 Arquivos no diretório:\")\n",
        "    for item in os.listdir('.'):\n",
        "        print(f\"  - {item}\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Diretório não encontrado: {project_path}\")\n",
        "    print(\"\\n🔍 Verificando estrutura do Drive...\")\n",
        "\n",
        "    # Verificar estrutura do Drive\n",
        "    base_path = '/content/drive/MyDrive'\n",
        "    if os.path.exists(base_path):\n",
        "        print(f\"\\n📁 Conteúdo de {base_path}:\")\n",
        "        for item in os.listdir(base_path):\n",
        "            print(f\"  - {item}\")\n",
        "\n",
        "    # Criar diretório se não existir\n",
        "    print(f\"\\n🔧 Criando diretório: {project_path}\")\n",
        "    os.makedirs(project_path, exist_ok=True)\n",
        "    os.chdir(project_path)\n",
        "    print(\"✅ Diretório criado e definido como atual\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SgQH75YHr3D",
        "outputId": "accf8ac7-2519-47ee-b726-3f44bfe1a425"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Diretório encontrado: /content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto\n",
            "📁 Diretório atual: /content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto\n",
            "\n",
            "📋 Arquivos no diretório:\n",
            "  - Detection of fake news using deep learning CNN–RNN based methods.pdf\n",
            "  - fake-news-classifier-naive-bayes.ipynb\n",
            "  - classificacao_fake_news_multimodelos-1.pdf\n",
            "  - Fake News Dataset.zip\n",
            "  - fake_news_dataset_multimodel.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAVVX3Y9z3A4",
        "outputId": "552775b3-321e-4ad1-d901-20b822b87e3b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Carregando dataset com verificação de cache...\n",
            "📁 Diretório do projeto: /content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto\n",
            "📦 Arquivo ZIP: Fake News Dataset.zip\n",
            "💾 Arquivo processado: fake_news_processed.csv\n",
            "\n",
            "============================================================\n",
            "🧠 SISTEMA DE CACHE INTELIGENTE\n",
            "============================================================\n",
            "✅ Dataset processado encontrado e atualizado\n",
            "⚡ Usando dataset em cache...\n",
            "📊 Carregando dataset processado...\n",
            "✅ Dataset carregado: 76,537 registros\n",
            "✅ Dataset carregado do cache com sucesso!\n",
            "\n",
            "============================================================\n",
            "📊 DATASET CARREGADO COM SUCESSO!\n",
            "============================================================\n",
            "📍 Fonte: 💾 CACHE\n",
            "📊 Estatísticas:\n",
            "   - Total de registros: 76,537\n",
            "   - 0 (Fake): 38,434 registros (50.2%)\n",
            "   - 1 (Real): 38,103 registros (49.8%)\n",
            "   - Comprimento médio do texto: 2197.3 caracteres\n",
            "\n",
            "⚡ Vantagens do cache:\n",
            "   - Carregamento instantâneo\n",
            "   - Sem necessidade de reprocessamento\n",
            "   - Dados já limpos e validados\n",
            "============================================================\n",
            "\n",
            "📋 Exemplos dos dados:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "🏷️  FAKE NEWS:\n",
            "   📄 finally get work post november davidswanson dear democrat find suddenly bit doubtful wisdom drone war presidential war without congress massive investment new small usable nuclear weapon expansion bas...\n",
            "\n",
            "🏷️  REAL NEWS:\n",
            "   📄 putin tell merkel un peacekeeper could deploy donbas contact line moscow reuters russian president vladimir putin told german chancellor angela merkel monday un peacekeeper might deploy eastern ukrain...\n",
            "--------------------------------------------------------------------------------\n",
            "🎉 Dataset pronto para uso! Variável 'data' contém 76,537 registros\n",
            "\n",
            "💡 Para forçar reprocessamento, execute: data, from_cache = force_reprocess()\n"
          ]
        }
      ],
      "source": [
        "# ================================================\n",
        "# CARREGAR DATASET COM CACHE INTELIGENTE\n",
        "# ================================================\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"🚀 Carregando dataset com verificação de cache...\")\n",
        "\n",
        "# ================================================\n",
        "# 1. CONFIGURAR CAMINHOS (VARIÁVEIS GLOBAIS)\n",
        "# ================================================\n",
        "\n",
        "# Caminhos no Google Drive\n",
        "project_dir = '/content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto'\n",
        "drive_zip_path = os.path.join(project_dir, 'Fake News Dataset.zip')\n",
        "processed_csv_path = os.path.join(project_dir, 'fake_news_processed.csv')\n",
        "metadata_path = os.path.join(project_dir, 'dataset_metadata.txt')\n",
        "\n",
        "# Diretório temporário para extração\n",
        "extract_dir = '/tmp/fake_news_data'\n",
        "\n",
        "print(f\"📁 Diretório do projeto: {project_dir}\")\n",
        "print(f\"📦 Arquivo ZIP: {os.path.basename(drive_zip_path)}\")\n",
        "print(f\"💾 Arquivo processado: {os.path.basename(processed_csv_path)}\")\n",
        "\n",
        "# ================================================\n",
        "# 2. VERIFICAR SE DATASET PROCESSADO JÁ EXISTE\n",
        "# ================================================\n",
        "\n",
        "def check_processed_dataset():\n",
        "    \"\"\"Verifica se o dataset processado já existe e está atualizado\"\"\"\n",
        "\n",
        "    if not os.path.exists(processed_csv_path):\n",
        "        print(\"❌ Dataset processado não encontrado\")\n",
        "        return False\n",
        "\n",
        "    if not os.path.exists(drive_zip_path):\n",
        "        print(\"⚠️  Arquivo ZIP original não encontrado, mas dataset processado existe\")\n",
        "        return True\n",
        "\n",
        "    # Comparar datas de modificação\n",
        "    zip_mtime = os.path.getmtime(drive_zip_path)\n",
        "    csv_mtime = os.path.getmtime(processed_csv_path)\n",
        "\n",
        "    if zip_mtime > csv_mtime:\n",
        "        print(\"⚠️  Arquivo ZIP é mais recente que o dataset processado\")\n",
        "        return False\n",
        "\n",
        "    # Verificar se o arquivo não está vazio\n",
        "    try:\n",
        "        df_test = pd.read_csv(processed_csv_path, nrows=1)\n",
        "        if len(df_test.columns) < 2:\n",
        "            print(\"⚠️  Dataset processado parece estar corrompido\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Erro ao verificar dataset processado: {e}\")\n",
        "        return False\n",
        "\n",
        "    print(\"✅ Dataset processado encontrado e atualizado\")\n",
        "    return True\n",
        "\n",
        "# ================================================\n",
        "# 3. CARREGAR DATASET PROCESSADO\n",
        "# ================================================\n",
        "\n",
        "def load_processed_dataset():\n",
        "    \"\"\"Carrega o dataset já processado\"\"\"\n",
        "\n",
        "    print(\"📊 Carregando dataset processado...\")\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(processed_csv_path)\n",
        "\n",
        "        # Validações básicas\n",
        "        required_columns = ['text', 'label']\n",
        "        if not all(col in data.columns for col in required_columns):\n",
        "            raise ValueError(f\"Colunas necessárias não encontradas: {required_columns}\")\n",
        "\n",
        "        # Verificar tipos de dados\n",
        "        if not pd.api.types.is_numeric_dtype(data['label']):\n",
        "            print(\"🔧 Convertendo coluna 'label' para numérico...\")\n",
        "            data['label'] = pd.to_numeric(data['label'], errors='coerce')\n",
        "            data = data.dropna(subset=['label'])\n",
        "            data['label'] = data['label'].astype(int)\n",
        "\n",
        "        # Remover linhas vazias\n",
        "        initial_len = len(data)\n",
        "        data = data.dropna(subset=['text', 'label'])\n",
        "        data = data[data['text'].astype(str).str.strip() != '']\n",
        "\n",
        "        if len(data) < initial_len:\n",
        "            print(f\"🧹 Removidas {initial_len - len(data)} linhas vazias/inválidas\")\n",
        "\n",
        "        print(f\"✅ Dataset carregado: {len(data):,} registros\")\n",
        "        return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao carregar dataset processado: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================================================\n",
        "# 4. PROCESSAR DATASET ORIGINAL (FUNÇÕES EXISTENTES)\n",
        "# ================================================\n",
        "\n",
        "def detect_delimiter(file_path, sample_size=1024):\n",
        "    \"\"\"Detecta automaticamente o delimitador do arquivo CSV\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            sample = f.read(sample_size)\n",
        "    except UnicodeDecodeError:\n",
        "        with open(file_path, 'r', encoding='latin-1') as f:\n",
        "            sample = f.read(sample_size)\n",
        "\n",
        "    delimiters = [',', ';', '\\t', '|']\n",
        "    counts = {delim: sample.count(delim) for delim in delimiters}\n",
        "    best_delim = max(counts, key=counts.get)\n",
        "    return best_delim if counts[best_delim] > 0 else ','\n",
        "\n",
        "def process_csv_file(file_path):\n",
        "    \"\"\"Processa um arquivo CSV individual\"\"\"\n",
        "    try:\n",
        "        delimiter = detect_delimiter(file_path)\n",
        "\n",
        "        encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "        df = None\n",
        "\n",
        "        for encoding in encodings:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding)\n",
        "                break\n",
        "            except UnicodeDecodeError:\n",
        "                continue\n",
        "\n",
        "        if df is None:\n",
        "            raise ValueError(\"Não foi possível ler o arquivo com nenhum encoding\")\n",
        "\n",
        "        # Renomear colunas se necessário\n",
        "        if 'text;label' in df.columns:\n",
        "            df[['text', 'label']] = df['text;label'].str.split(';', n=1, expand=True)\n",
        "            df = df.drop(columns=['text;label'])\n",
        "\n",
        "        # Garantir que temos as colunas necessárias\n",
        "        if 'text' not in df.columns or 'label' not in df.columns:\n",
        "            text_cols = [col for col in df.columns if any(keyword in col.lower()\n",
        "                        for keyword in ['text', 'content', 'news', 'article', 'title'])]\n",
        "            label_cols = [col for col in df.columns if any(keyword in col.lower()\n",
        "                         for keyword in ['label', 'class', 'target', 'fake', 'real'])]\n",
        "\n",
        "            if text_cols and label_cols:\n",
        "                df = df.rename(columns={text_cols[0]: 'text', label_cols[0]: 'label'})\n",
        "            else:\n",
        "                if len(df.columns) == 1:\n",
        "                    col_name = df.columns[0]\n",
        "                    if ';' in str(df.iloc[0, 0]):\n",
        "                        df_split = df[col_name].str.split(';', expand=True)\n",
        "                        if df_split.shape[1] >= 2:\n",
        "                            df = df_split.rename(columns={0: 'text', 1: 'label'})\n",
        "\n",
        "        if 'text' not in df.columns or 'label' not in df.columns:\n",
        "            return None\n",
        "\n",
        "        # Processar rótulos\n",
        "        df['label'] = df['label'].astype(str).str.strip().str.lower()\n",
        "\n",
        "        label_mapping = {\n",
        "            'real': 1, 'true': 1, 'reliable': 1, 'legitimate': 1,\n",
        "            'fake': 0, 'false': 0, 'unreliable': 0, 'illegitimate': 0,\n",
        "            'verdadeiro': 1, 'verdadeira': 1, 'confiável': 1,\n",
        "            'falso': 0, 'falsa': 0, 'não confiável': 0,\n",
        "            '1': 1, '1.0': 1, '0': 0, '0.0': 0,\n",
        "            'yes': 1, 'no': 0, 'sim': 1, 'não': 0, 'nao': 0\n",
        "        }\n",
        "\n",
        "        df['label'] = df['label'].map(label_mapping)\n",
        "        df = df.dropna(subset=['label'])\n",
        "        df['label'] = df['label'].astype(int)\n",
        "\n",
        "        # Limpeza de texto\n",
        "        df = df.dropna(subset=['text'])\n",
        "        df['text'] = df['text'].astype(str).str.strip()\n",
        "        df = df[df['text'] != '']\n",
        "        df = df[df['text'] != 'nan']\n",
        "\n",
        "        return df, delimiter\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"🚨 Erro ao processar {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def find_zip_file():\n",
        "    \"\"\"Encontra o arquivo ZIP no diretório do projeto\"\"\"\n",
        "    global drive_zip_path\n",
        "\n",
        "    # Verificar se arquivo ZIP padrão existe\n",
        "    if os.path.exists(drive_zip_path):\n",
        "        return drive_zip_path\n",
        "\n",
        "    print(f\"❌ Arquivo ZIP padrão não encontrado: {os.path.basename(drive_zip_path)}\")\n",
        "\n",
        "    # Buscar arquivos ZIP no diretório\n",
        "    if os.path.exists(project_dir):\n",
        "        print(\"🔍 Procurando arquivos ZIP no diretório...\")\n",
        "        zip_files = [f for f in os.listdir(project_dir) if f.lower().endswith('.zip')]\n",
        "\n",
        "        if zip_files:\n",
        "            # Usar o primeiro arquivo ZIP encontrado\n",
        "            new_zip_path = os.path.join(project_dir, zip_files[0])\n",
        "            print(f\"💡 Arquivo ZIP encontrado: {zip_files[0]}\")\n",
        "\n",
        "            # Atualizar variável global\n",
        "            drive_zip_path = new_zip_path\n",
        "            return drive_zip_path\n",
        "        else:\n",
        "            print(\"❌ Nenhum arquivo ZIP encontrado no diretório\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"❌ Diretório do projeto não encontrado\")\n",
        "        return None\n",
        "\n",
        "def process_original_dataset():\n",
        "    \"\"\"Processa o dataset original do arquivo ZIP\"\"\"\n",
        "\n",
        "    print(\"🔄 Processando dataset original...\")\n",
        "\n",
        "    # Encontrar arquivo ZIP\n",
        "    zip_file_path = find_zip_file()\n",
        "    if not zip_file_path:\n",
        "        raise FileNotFoundError(\"Nenhum arquivo ZIP encontrado!\")\n",
        "\n",
        "    # Extrair arquivo ZIP\n",
        "    print(f\"📦 Extraindo arquivo ZIP: {os.path.basename(zip_file_path)}\")\n",
        "    try:\n",
        "        os.makedirs(extract_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "        print(f\"✅ Arquivo extraído para: {extract_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao extrair arquivo: {e}\")\n",
        "        raise\n",
        "\n",
        "    # Encontrar arquivos CSV\n",
        "    csv_files_found = []\n",
        "    for root, dirs, files in os.walk(extract_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.csv'):\n",
        "                csv_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    print(f\"🔍 Arquivos CSV encontrados: {len(csv_files_found)}\")\n",
        "\n",
        "    if not csv_files_found:\n",
        "        print(\"❌ Nenhum arquivo CSV encontrado no ZIP\")\n",
        "        # Listar conteúdo do ZIP para debug\n",
        "        print(\"📋 Conteúdo extraído:\")\n",
        "        for root, dirs, files in os.walk(extract_dir):\n",
        "            level = root.replace(extract_dir, '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f\"{indent}📁 {os.path.basename(root)}/\")\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files:\n",
        "                print(f\"{subindent}📄 {file}\")\n",
        "        raise ValueError(\"Nenhum arquivo CSV encontrado!\")\n",
        "\n",
        "    # Processar arquivos CSV\n",
        "    all_dfs = []\n",
        "    processed_files = []\n",
        "\n",
        "    for file_path in csv_files_found:\n",
        "        print(f\"📄 Processando: {os.path.basename(file_path)}\")\n",
        "\n",
        "        result = process_csv_file(file_path)\n",
        "\n",
        "        if result is not None:\n",
        "            df, delimiter = result\n",
        "            all_dfs.append(df)\n",
        "            processed_files.append(file_path)\n",
        "            print(f\"✅ Processado: {os.path.basename(file_path)} | Registros: {len(df)}\")\n",
        "        else:\n",
        "            print(f\"❌ Falha ao processar: {os.path.basename(file_path)}\")\n",
        "\n",
        "    if not all_dfs:\n",
        "        raise ValueError(\"Nenhum dataset válido foi processado!\")\n",
        "\n",
        "    # Combinar datasets\n",
        "    print(f\"🔗 Combinando {len(all_dfs)} datasets...\")\n",
        "    data = pd.concat(all_dfs, ignore_index=True)\n",
        "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    return data, processed_files\n",
        "\n",
        "def save_processed_dataset(data, processed_files):\n",
        "    \"\"\"Salva o dataset processado e metadados\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Salvar dataset\n",
        "        data.to_csv(processed_csv_path, index=False, encoding='utf-8')\n",
        "        print(f\"💾 Dataset salvo em: {os.path.basename(processed_csv_path)}\")\n",
        "\n",
        "        # Salvar metadados\n",
        "        metadata = {\n",
        "            'processed_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'total_records': len(data),\n",
        "            'processed_files': len(processed_files),\n",
        "            'label_distribution': data['label'].value_counts().to_dict(),\n",
        "            'text_stats': {\n",
        "                'avg_length': float(data['text'].str.len().mean()),\n",
        "                'min_length': int(data['text'].str.len().min()),\n",
        "                'max_length': int(data['text'].str.len().max())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(metadata_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"FAKE NEWS DATASET - METADATA\\n\")\n",
        "            f.write(\"=\"*40 + \"\\n\")\n",
        "            for key, value in metadata.items():\n",
        "                f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "        print(f\"📋 Metadados salvos em: {os.path.basename(metadata_path)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️  Erro ao salvar arquivos: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 5. LÓGICA PRINCIPAL COM CACHE\n",
        "# ================================================\n",
        "\n",
        "def load_dataset_with_cache():\n",
        "    \"\"\"Carrega dataset usando cache inteligente\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🧠 SISTEMA DE CACHE INTELIGENTE\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Verificar se dataset processado existe e está atualizado\n",
        "    if check_processed_dataset():\n",
        "        print(\"⚡ Usando dataset em cache...\")\n",
        "\n",
        "        data = load_processed_dataset()\n",
        "\n",
        "        if data is not None:\n",
        "            print(\"✅ Dataset carregado do cache com sucesso!\")\n",
        "            return data, True  # True indica que foi carregado do cache\n",
        "        else:\n",
        "            print(\"❌ Falha ao carregar do cache, processando novamente...\")\n",
        "\n",
        "    # Se chegou aqui, precisa processar o dataset original\n",
        "    print(\"🔄 Processando dataset original...\")\n",
        "\n",
        "    try:\n",
        "        data, processed_files = process_original_dataset()\n",
        "\n",
        "        # Salvar dataset processado para uso futuro\n",
        "        save_processed_dataset(data, processed_files)\n",
        "\n",
        "        print(\"✅ Dataset processado e salvo com sucesso!\")\n",
        "        return data, False  # False indica que foi processado agora\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro no processamento: {e}\")\n",
        "        raise\n",
        "\n",
        "# ================================================\n",
        "# 6. EXECUTAR CARREGAMENTO\n",
        "# ================================================\n",
        "\n",
        "try:\n",
        "    # Carregar dataset\n",
        "    data, from_cache = load_dataset_with_cache()\n",
        "\n",
        "    # ================================================\n",
        "    # 7. EXIBIR RESULTADOS\n",
        "    # ================================================\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"📊 DATASET CARREGADO COM SUCESSO!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Indicar fonte dos dados\n",
        "    source_info = \"💾 CACHE\" if from_cache else \"🔄 PROCESSAMENTO ORIGINAL\"\n",
        "    print(f\"📍 Fonte: {source_info}\")\n",
        "\n",
        "    # Estatísticas do dataset\n",
        "    print(f\"📊 Estatísticas:\")\n",
        "    print(f\"   - Total de registros: {len(data):,}\")\n",
        "\n",
        "    label_counts = data['label'].value_counts().sort_index()\n",
        "    for label, count in label_counts.items():\n",
        "        label_name = \"Real\" if label == 1 else \"Fake\"\n",
        "        percentage = (count / len(data)) * 100\n",
        "        print(f\"   - {label} ({label_name}): {count:,} registros ({percentage:.1f}%)\")\n",
        "\n",
        "    print(f\"   - Comprimento médio do texto: {data['text'].str.len().mean():.1f} caracteres\")\n",
        "\n",
        "    # Mostrar informações de cache\n",
        "    if from_cache:\n",
        "        print(f\"\\n⚡ Vantagens do cache:\")\n",
        "        print(f\"   - Carregamento instantâneo\")\n",
        "        print(f\"   - Sem necessidade de reprocessamento\")\n",
        "        print(f\"   - Dados já limpos e validados\")\n",
        "    else:\n",
        "        print(f\"\\n🔄 Dataset processado e salvo:\")\n",
        "        print(f\"   - Próxima execução será mais rápida\")\n",
        "        print(f\"   - Cache criado automaticamente\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # ================================================\n",
        "    # 8. EXEMPLOS DOS DADOS\n",
        "    # ================================================\n",
        "\n",
        "    print(\"\\n📋 Exemplos dos dados:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for label in [0, 1]:\n",
        "        label_name = \"FAKE NEWS\" if label == 0 else \"REAL NEWS\"\n",
        "        sample = data[data['label'] == label].sample(n=1, random_state=42)\n",
        "\n",
        "        print(f\"\\n🏷️  {label_name}:\")\n",
        "        for idx, row in sample.iterrows():\n",
        "            text_preview = row['text'][:200] + \"...\" if len(row['text']) > 200 else row['text']\n",
        "            print(f\"   📄 {text_preview}\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"🎉 Dataset pronto para uso! Variável 'data' contém {len(data):,} registros\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERRO CRÍTICO: {e}\")\n",
        "    print(\"💡 Verifique se:\")\n",
        "    print(\"   - O Google Drive está montado corretamente\")\n",
        "    print(\"   - O arquivo ZIP existe no diretório do projeto\")\n",
        "    print(\"   - Você tem permissões de leitura/escrita\")\n",
        "\n",
        "# ================================================\n",
        "# 9. FUNÇÃO PARA FORÇAR REPROCESSAMENTO (OPCIONAL)\n",
        "# ================================================\n",
        "\n",
        "def force_reprocess():\n",
        "    \"\"\"Força o reprocessamento do dataset, ignorando cache\"\"\"\n",
        "\n",
        "    print(\"🔄 Forçando reprocessamento...\")\n",
        "\n",
        "    # Remover arquivos de cache\n",
        "    files_to_remove = [processed_csv_path, metadata_path]\n",
        "\n",
        "    for file_path in files_to_remove:\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"🗑️  Removido: {os.path.basename(file_path)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️  Erro ao remover {os.path.basename(file_path)}: {e}\")\n",
        "\n",
        "    # Reprocessar\n",
        "    return load_dataset_with_cache()\n",
        "\n",
        "# Para forçar reprocessamento, descomente a linha abaixo:\n",
        "# data, from_cache = force_reprocess()\n",
        "\n",
        "print(f\"\\n💡 Para forçar reprocessamento, execute: data, from_cache = force_reprocess()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK8WhsxlOpma"
      },
      "source": [
        "3. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k06zUuc9OrwL",
        "outputId": "a1e18e22-bc24-4b1e-ec7c-d9b0035c5c49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#used for data cleaning\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  #removes punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  #removes numbers\n",
        "    text = text.lower()  #turns everything to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words]) #gets rid of stop words\n",
        "    return text\n",
        "\n",
        "data['text'] = data['text'].apply(clean_text) #applies changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2jHlEQUrv6_"
      },
      "source": [
        "3. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OoOa28EWz-R_"
      },
      "outputs": [],
      "source": [
        "#some train test splitting, 20%\n",
        "X = data['text']\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=142857)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMRvnHky0Adv"
      },
      "source": [
        "# 4. Bag of Words + Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5q8KDaoa0BX3"
      },
      "outputs": [],
      "source": [
        "bow = CountVectorizer(max_features=5000)\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_test_bow = bow.transform(X_test)\n",
        "bow_model = MultinomialNB()\n",
        "bow_model.fit(X_train_bow, y_train)\n",
        "y_pred_bow = bow_model.predict(X_test_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZoT9Drc0GPP"
      },
      "source": [
        "5. TF-IDF + Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uqdn0Hwl0Jmf"
      },
      "outputs": [],
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "tfidf_model = LogisticRegression(max_iter=1000)\n",
        "tfidf_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_tfidf = tfidf_model.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryyJG0ZeQwYt",
        "outputId": "e8996f2b-ba2e-445d-ac80-2aa2050fb638",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Carrega o modelo com vetores pré-treinados (~100MB, mais leve que Word2Vec do Google)\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qgmwu2O0NiY"
      },
      "source": [
        "6. Word2Vec + Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aCH68lwh0RRX"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Carrega o modelo com embeddings pré-treinados (~100MB)\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Função para vetorizar textos com spaCy\n",
        "def vectorize_spacy(texts):\n",
        "    vectors = []\n",
        "    for doc in nlp.pipe(texts, disable=[\"ner\", \"parser\"]):\n",
        "        vectors.append(doc.vector)\n",
        "    return np.array(vectors)\n",
        "\n",
        "# Vetorização dos conjuntos de treino e teste\n",
        "X_train_w2v = vectorize_spacy(X_train)\n",
        "X_test_w2v = vectorize_spacy(X_test)\n",
        "\n",
        "# Classificador com Random Forest\n",
        "w2v_model_clf = RandomForestClassifier()\n",
        "w2v_model_clf.fit(X_train_w2v, y_train)\n",
        "y_pred_w2v = w2v_model_clf.predict(X_test_w2v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG7JbInm0SII"
      },
      "source": [
        "# 7. GloVe + XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U2yl0rmg0UuA"
      },
      "outputs": [],
      "source": [
        "# Simulando GloVe com Word2Vec para simplificar, mas pode-se usar GloVe real\n",
        "X_train_glove = X_train_w2v\n",
        "X_test_glove = X_test_w2v\n",
        "glove_model = XGBClassifier(eval_metric='logloss')\n",
        "glove_model.fit(X_train_glove, y_train)\n",
        "y_pred_glove = glove_model.predict(X_test_glove)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8SMUns20VVA"
      },
      "source": [
        "8. BERT + Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "69216df7ecf44c0ba878a93c1530ebcf",
            "a00c936f5c2440a1bf6eb8860a29d9c9",
            "0ad01008b409438da136de0eeaa8378f",
            "95a363294aa64993b28471a614da97ef",
            "b904633988434cb782b8c2fc4d31b870",
            "dafa6dcb99d546eeb7e6008cbbaa9f8a",
            "b68305c0b4794aacacec797abec699d9",
            "23a7892dda95456d860da010511e36b4",
            "f240cd219d1a4540ad7c7b9379253cbe",
            "6208cd3114384e9ebc27e9e107ffd429",
            "8017d3670bb24ce1a13535be5a632ab6",
            "f24f2f5aa11f4287aa6fd9e00e88dac5",
            "ae8536e81bc24759ad1067a80be3937b",
            "b1f8c37fe40946c0ad3d5a30beba9986",
            "7dd05fa3eb2044498840326170541925",
            "e177e5212d08444eabbd23d778463879",
            "38bd088993d24bf4a7ff6c03eecc8e27",
            "ec85cc8ec3314b0ba21286ea017e6a62",
            "9f386e360b30494ea04a38e036e0fc05",
            "11d793e01e744d2ab230bf3ecb882dee",
            "1dffa3931cd540e8aae943de6d1fc475",
            "3775c470eb2b477191ecaa65a855f0ba",
            "a057d9f84b6d4aeca91000746b39c668",
            "94711dceb9484598a2c361321fd57809",
            "8532749ce1dd4a3e906e513142b58866",
            "1fdbf2e6b1ba459f8e9b410403c3652c",
            "3587ed801fb944548898f6f9d06a9bde",
            "b26e0d239cf54b149e8b5bd769b47b6a",
            "8ac7cccdbb81406783e1bebdec27739a",
            "c1196076846e4c42b9921c01c5ed0a50",
            "aa87ecd7bd884036a71cb15235f713d4",
            "e641e50708334cb6ada8348a9c781260",
            "e638c9acf88a469c8ddbbe982be926f2",
            "ac98e4066b5d4a06a5ce45d86b6b01e4",
            "b0f6ae52d67448adab9e630c5e61ab48",
            "0753e3136ce84c10a5669f792cb6fece",
            "e3bc6f9dc542445bb40ac8524ad84ef2",
            "1e5897fb55bb4b9b9e734c643ca4a91a",
            "fb99e3d93ba34c85a67bd5b317ee2842",
            "1eec6b08fe5040d88f8f470ac899677f",
            "b44390415c3946cfa19835389a6d1e8d",
            "40b162589d41435cad0a6c23a60d59ef",
            "864adc25079145fc8facaba484ec4bc3",
            "b9afe98c956140b2bc0bd0d6b4d6dddc",
            "395f34276a3d4bf18badf99ab98e3d42",
            "95e14e4902e64c109f3f6324e0e8cc90",
            "ff7d62c0d56446d686dca272d411dd8c",
            "142255d417d64fefb6a81aaa22f19412",
            "d4b53be33fce4648a78ea937ab4e7513",
            "a8cbc107e90d4644bcd8f9bcb7f16cac",
            "d1d0f3978a424b92afb85b42effc63ba",
            "e62a380a40d0493684fc5fa625933253",
            "2f9058f327a040118404ea765474b5ae",
            "07d438e0833f40a99690aa0628fb2f2a",
            "72b5258f2d024e0a9d3d12c4d4f78bcf"
          ]
        },
        "id": "xVcufBzU0acg",
        "outputId": "29b59231-612d-4430-b40d-929f0d6667c3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69216df7ecf44c0ba878a93c1530ebcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24f2f5aa11f4287aa6fd9e00e88dac5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a057d9f84b6d4aeca91000746b39c668"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac98e4066b5d4a06a5ce45d86b6b01e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "395f34276a3d4bf18badf99ab98e3d42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mffcs\u001b[0m (\u001b[33mffcs-cin-ufpe\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Doutorado/2025.2/Deep Learning/projeto/wandb/run-20250616_154117-906hlhua</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ffcs-cin-ufpe/huggingface/runs/906hlhua' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/ffcs-cin-ufpe/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ffcs-cin-ufpe/huggingface' target=\"_blank\">https://wandb.ai/ffcs-cin-ufpe/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ffcs-cin-ufpe/huggingface/runs/906hlhua' target=\"_blank\">https://wandb.ai/ffcs-cin-ufpe/huggingface/runs/906hlhua</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class FakeNewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.encodings = tokenizer(list(texts), truncation=True, padding=True, max_length=max_len)\n",
        "        self.labels = list(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "train_dataset = FakeNewsDataset(X_train[:2000], y_train[:2000], tokenizer)\n",
        "test_dataset = FakeNewsDataset(X_test[:500], y_test[:500], tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"./results\", per_device_train_batch_size=8, per_device_eval_batch_size=8, num_train_epochs=2, logging_dir=\"./logs\", logging_steps=10)\n",
        "\n",
        "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset)\n",
        "trainer.train()\n",
        "preds = trainer.predict(test_dataset)\n",
        "y_pred_bert = np.argmax(preds.predictions, axis=1)\n",
        "y_true_bert = y_test[:500].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcf5UvSa0by4"
      },
      "source": [
        "# 9. Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khFMjdmV0eKx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def evaluate(name, y_true, y_pred):\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
        "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
        "    print(\"F1-score:\", f1_score(y_true, y_pred))\n",
        "\n",
        "evaluate(\"Bag of Words + NB\", y_test, y_pred_bow)\n",
        "evaluate(\"TF-IDF + LR\", y_test, y_pred_tfidf)\n",
        "evaluate(\"Word2Vec + RF\", y_test, y_pred_w2v)\n",
        "evaluate(\"GloVe + XGBoost\", y_test, y_pred_glove)\n",
        "evaluate(\"BERT\", y_true_bert, y_pred_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaY2808-9dQB"
      },
      "source": [
        "10. Matriz de confusao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLQeyG_I9gVJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Função para plotar a matriz de confusão\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['Fake', 'True'],\n",
        "                yticklabels=['Fake', 'True'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(f'Matriz de Confusão - {model_name}')\n",
        "    plt.show()\n",
        "\n",
        "# Plotar as matrizes de confusão para cada modelo\n",
        "plot_confusion_matrix(y_test, y_pred_bow, 'BoW + NB')\n",
        "plot_confusion_matrix(y_test, y_pred_tfidf, 'TF-IDF + LR')\n",
        "plot_confusion_matrix(y_test, y_pred_w2v, 'Word2Vec + RF')\n",
        "plot_confusion_matrix(y_test, y_pred_glove, 'GloVe + XGB')\n",
        "plot_confusion_matrix(y_true_bert, y_pred_bert, 'BERT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Q2X_Hi989t"
      },
      "source": [
        "11. Gerando gráficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7gh3iud-DEH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Função para plotar as métricas dos modelos\n",
        "def plot_metrics(models, metrics):\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    x = range(len(models))\n",
        "    width = 0.2\n",
        "\n",
        "    for i, (metric_name, metric_values) in enumerate(metrics.items()):\n",
        "        ax.bar([pos + width * i for pos in x], metric_values, width, label=metric_name)\n",
        "\n",
        "    ax.set_xticks([pos + width for pos in x])\n",
        "    ax.set_xticklabels(models)\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Performance dos Modelos')\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "    plt.ylim(0, 1.1)\n",
        "    plt.show()\n",
        "\n",
        "# Dados dos modelos e métricas\n",
        "models = ['BoW + NB', 'TF-IDF + LR', 'Word2Vec + RF', 'GloVe + XGB', 'BERT']\n",
        "metrics = {\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_bow),\n",
        "        accuracy_score(y_test, y_pred_tfidf),\n",
        "        accuracy_score(y_test, y_pred_w2v),\n",
        "        accuracy_score(y_test, y_pred_glove),\n",
        "        accuracy_score(y_true_bert, y_pred_bert)\n",
        "    ],\n",
        "    'Precision': [\n",
        "        precision_score(y_test, y_pred_bow),\n",
        "        precision_score(y_test, y_pred_tfidf),\n",
        "        precision_score(y_test, y_pred_w2v),\n",
        "        precision_score(y_test, y_pred_glove),\n",
        "        precision_score(y_true_bert, y_pred_bert)\n",
        "    ],\n",
        "    'Recall': [\n",
        "        recall_score(y_test, y_pred_bow),\n",
        "        recall_score(y_test, y_pred_tfidf),\n",
        "        recall_score(y_test, y_pred_w2v),\n",
        "        recall_score(y_test, y_pred_glove),\n",
        "        recall_score(y_true_bert, y_pred_bert)\n",
        "    ],\n",
        "    'F1-score': [\n",
        "        f1_score(y_test, y_pred_bow),\n",
        "        f1_score(y_test, y_pred_tfidf),\n",
        "        f1_score(y_test, y_pred_w2v),\n",
        "        f1_score(y_test, y_pred_glove),\n",
        "        f1_score(y_true_bert, y_pred_bert)\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Plotar as métricas\n",
        "plot_metrics(models, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k00U8qzU9wxp"
      },
      "source": [
        "12. Otimizando os hiperparametros com Optuna para BoW + Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBxznWqGUZLt",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Função de objetivo para o Naive Bayes\n",
        "def objective_nb(trial):\n",
        "    # Hiperparâmetros a serem otimizados\n",
        "    params = {\n",
        "        'alpha': trial.suggest_float('alpha', 0.01, 10.0, log=True),  # Suavização de Laplace\n",
        "        'fit_prior': trial.suggest_categorical('fit_prior', [True, False])  # Aprender priors\n",
        "    }\n",
        "\n",
        "    # Modelo e avaliação com validação cruzada\n",
        "    model = MultinomialNB(**params)\n",
        "    score = cross_val_score(model, X_train_bow, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "# Executar otimização\n",
        "study_nb = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_nb.optimize(objective_nb, n_trials=20, n_jobs=-1)\n",
        "\n",
        "# Melhores hiperparâmetros\n",
        "print(\"Melhores parâmetros para Naive Bayes:\", study_nb.best_params)\n",
        "optuna.visualization.plot_optimization_history(study_nb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA26rtNtU9lR"
      },
      "source": [
        "13. Otimizando o modelo TF-IDF com Regressao Logistica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI34yZrlVDsY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_lr(trial):\n",
        "    # Hiperparâmetros a serem otimizados\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
        "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "        'solver': trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
        "    }\n",
        "\n",
        "    # Modelo e avaliação com validação cruzada\n",
        "    model = LogisticRegression(**params, max_iter=100)\n",
        "    score = cross_val_score(model, X_train_tfidf, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "# Otimização\n",
        "study_lr = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_lr.optimize(objective_lr, n_trials=10, n_jobs=-1)\n",
        "\n",
        "# Melhores hiperparâmetros\n",
        "print(\"Melhores parâmetros para LR:\", study_lr.best_params)\n",
        "optuna.visualization.plot_optimization_history(study_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2GjNuvXVKW0"
      },
      "source": [
        "14. Otimizando o modelo Random Forest + Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJkdTh6pVRnG"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_rf(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**params)\n",
        "    score = cross_val_score(model, X_train_w2v, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "study_rf = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_rf.optimize(objective_rf, n_trials=5, n_jobs=-1)\n",
        "optuna.visualization.plot_optimization_history(study_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TubF1bEpVYCF"
      },
      "source": [
        "15. Otimizando o modelo do XGBoost + GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9iz5_8QVdvF"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_xgb(trial):\n",
        "    params = {\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200)\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params, eval_metric='logloss')\n",
        "    score = cross_val_score(model, X_train_glove, y_train, cv=3, scoring='f1').mean()\n",
        "    return score\n",
        "\n",
        "study_xgb = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "study_xgb.optimize(objective_xgb, n_trials=10, n_jobs=-1)\n",
        "optuna.visualization.plot_optimization_history(study_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skSIsST1VtJm"
      },
      "source": [
        "16. Otimizando o modelo BERT + Fine-Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMnXVoKyVy3j"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "def objective_bert(trial):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        learning_rate=trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n",
        "        per_device_train_batch_size=trial.suggest_categorical('batch_size', [8, 16]),\n",
        "        num_train_epochs=trial.suggest_int('num_epochs', 1, 3),\n",
        "        weight_decay=0.01,\n",
        "        eval_strategy=\"epoch\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    results = trainer.evaluate()\n",
        "    return results['eval_loss']  # Minimizar a perda\n",
        "\n",
        "study_bert = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
        "study_bert.optimize(objective_bert, n_trials=5, n_jobs=-1)\n",
        "optuna.visualization.plot_optimization_history(study_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyYPNv8kaT0A"
      },
      "source": [
        "17. Exibição das melhorias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZcDyXLvaWF_"
      },
      "outputs": [],
      "source": [
        "# ================================================\n",
        "# 1. Naive Bayes (NB) - Melhores Parâmetros\n",
        "# ================================================\n",
        "best_nb_params = study_nb.best_params\n",
        "best_nb_model = MultinomialNB(**best_nb_params)\n",
        "best_nb_model.fit(X_train_bow, y_train)\n",
        "y_pred_nb = best_nb_model.predict(X_test_bow)\n",
        "\n",
        "# Avaliação\n",
        "print(\"=== Naive Bayes (Otimizado) ===\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_nb))\n",
        "\n",
        "# ================================================\n",
        "# 2. Logistic Regression (TF-IDF) - Melhores Parâmetros\n",
        "# ================================================\n",
        "best_lr_params = study_lr.best_params\n",
        "best_lr_model = LogisticRegression(**best_lr_params, max_iter=100)\n",
        "best_lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = best_lr_model.predict(X_test_tfidf)\n",
        "\n",
        "# Avaliação\n",
        "print(\"=== Logistic Regression (Otimizado) ===\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_lr))\n",
        "\n",
        "# ================================================\n",
        "# 3. Random Forest (Word2Vec) - Melhores Parâmetros\n",
        "# ================================================\n",
        "best_rf_params = study_rf.best_params\n",
        "best_rf_model = RandomForestClassifier(**best_rf_params)\n",
        "best_rf_model.fit(X_train_w2v, y_train)\n",
        "y_pred_rf = best_rf_model.predict(X_test_w2v)\n",
        "\n",
        "# Avaliação\n",
        "print(\"\\\\n=== Random Forest (Otimizado) ===\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_rf))\n",
        "\n",
        "# ================================================\n",
        "# 4. XGBoost (GloVe) - Melhores Parâmetros\n",
        "# ================================================\n",
        "best_xgb_params = study_xgb.best_params\n",
        "best_xgb_model = XGBClassifier(**best_xgb_params, eval_metric='logloss')\n",
        "best_xgb_model.fit(X_train_glove, y_train)\n",
        "y_pred_xgb = best_xgb_model.predict(X_test_glove)\n",
        "\n",
        "# Avaliação\n",
        "print(\"\\\\n=== XGBoost (Otimizado) ===\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(\"F1-score:\", f1_score(y_test, y_pred_xgb))\n",
        "\n",
        "# ================================================\n",
        "# 5. BERT (Fine-Tuning) - Melhores Parâmetros\n",
        "# ================================================\n",
        "best_bert_params = study_bert.best_params\n",
        "\n",
        "# Configurar os argumentos de treino com os melhores parâmetros\n",
        "best_training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=best_bert_params['learning_rate'],\n",
        "    per_device_train_batch_size=best_bert_params['batch_size'],\n",
        "    num_train_epochs=best_bert_params['num_epochs'],\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Treinar o modelo final com todos os dados (sem validação cruzada)\n",
        "final_trainer = Trainer(\n",
        "    model=model,\n",
        "    args=best_training_args,\n",
        "    train_dataset=X_train,  # Use o dataset completo\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "final_trainer.train()\n",
        "\n",
        "# Fazer previsões finais\n",
        "preds = final_trainer.predict(test_dataset)\n",
        "y_pred_bert = np.argmax(preds.predictions, axis=1)\n",
        "\n",
        "# Avaliação\n",
        "print(\"\\\\n=== BERT (Otimizado) ===\")\n",
        "print(\"Acurácia:\", accuracy_score(y_true_bert, y_pred_bert))\n",
        "print(\"F1-score:\", f1_score(y_true_bert, y_pred_bert))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicabilidade"
      ],
      "metadata": {
        "id": "5NwGOY_le26y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# EXPLICABILIDADE DOS MODELOS\n",
        "# ================================================\n",
        "\n",
        "import shap\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Configurar SHAP\n",
        "shap.initjs()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANÁLISE DE EXPLICABILIDADE DOS MODELOS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ================================================\n",
        "# 1. PREPARAÇÃO DOS DADOS PARA EXPLICABILIDADE\n",
        "# ================================================\n",
        "\n",
        "# Selecionar algumas amostras para explicar\n",
        "n_samples_explain = 10\n",
        "sample_indices = np.random.choice(len(X_test), n_samples_explain, replace=False)\n",
        "sample_texts = [df_test.iloc[i]['text'] for i in sample_indices]  # Assumindo que você tem o texto original\n",
        "sample_labels = y_test.iloc[sample_indices] if hasattr(y_test, 'iloc') else y_test[sample_indices]\n",
        "\n",
        "print(f\"Analisando {n_samples_explain} amostras selecionadas aleatoriamente...\")\n",
        "\n",
        "# ================================================\n",
        "# 2. EXPLICABILIDADE COM SHAP\n",
        "# ================================================\n",
        "\n",
        "def explain_with_shap():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EXPLICABILIDADE COM SHAP\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 2.1 Logistic Regression (TF-IDF) - Linear Explainer\n",
        "    print(\"\\n--- Logistic Regression (TF-IDF) ---\")\n",
        "    try:\n",
        "        # Criar explainer para modelo linear\n",
        "        explainer_lr = shap.LinearExplainer(best_lr_model, X_train_tfidf)\n",
        "        shap_values_lr = explainer_lr.shap_values(X_test_tfidf[sample_indices])\n",
        "\n",
        "        # Obter nomes das features (palavras do vocabulário)\n",
        "        feature_names_tfidf = vectorizer_tfidf.get_feature_names_out()\n",
        "\n",
        "        # Visualização - Summary Plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values_lr, X_test_tfidf[sample_indices],\n",
        "                         feature_names=feature_names_tfidf, show=False, max_display=20)\n",
        "        plt.title(\"SHAP Summary Plot - Logistic Regression\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Waterfall plot para primeira amostra\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        shap.waterfall_plot(explainer_lr.expected_value, shap_values_lr[0],\n",
        "                           X_test_tfidf[sample_indices[0]], feature_names=feature_names_tfidf)\n",
        "        plt.title(f\"SHAP Waterfall Plot - Amostra 1 (Label: {sample_labels[0]})\")\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na explicabilidade LR: {e}\")\n",
        "\n",
        "    # 2.2 Random Forest (Word2Vec) - Tree Explainer\n",
        "    print(\"\\n--- Random Forest (Word2Vec) ---\")\n",
        "    try:\n",
        "        # Tree explainer para Random Forest\n",
        "        explainer_rf = shap.TreeExplainer(best_rf_model)\n",
        "        shap_values_rf = explainer_rf.shap_values(X_test_w2v[sample_indices])\n",
        "\n",
        "        # Se classificação binária, pegar apenas uma classe\n",
        "        if len(shap_values_rf) == 2:\n",
        "            shap_values_rf = shap_values_rf[1]\n",
        "\n",
        "        # Summary plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values_rf, X_test_w2v[sample_indices], show=False, max_display=20)\n",
        "        plt.title(\"SHAP Summary Plot - Random Forest\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na explicabilidade RF: {e}\")\n",
        "\n",
        "    # 2.3 XGBoost (GloVe) - Tree Explainer\n",
        "    print(\"\\n--- XGBoost (GloVe) ---\")\n",
        "    try:\n",
        "        # Tree explainer para XGBoost\n",
        "        explainer_xgb = shap.TreeExplainer(best_xgb_model)\n",
        "        shap_values_xgb = explainer_xgb.shap_values(X_test_glove[sample_indices])\n",
        "\n",
        "        # Summary plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values_xgb, X_test_glove[sample_indices], show=False, max_display=20)\n",
        "        plt.title(\"SHAP Summary Plot - XGBoost\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Feature importance global\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values_xgb, X_test_glove[sample_indices],\n",
        "                         plot_type=\"bar\", show=False, max_display=15)\n",
        "        plt.title(\"SHAP Feature Importance - XGBoost\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na explicabilidade XGB: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 3. EXPLICABILIDADE COM LIME (COMPARAÇÃO)\n",
        "# ================================================\n",
        "\n",
        "def explain_with_lime():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"EXPLICABILIDADE COM LIME (COMPARAÇÃO)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Criar explainer LIME para texto\n",
        "    explainer_lime = LimeTextExplainer(class_names=['Negativo', 'Positivo'])\n",
        "\n",
        "    # Função de predição para LIME (usando Logistic Regression)\n",
        "    def predict_proba_lr(texts):\n",
        "        # Transformar textos usando o mesmo pipeline\n",
        "        texts_tfidf = vectorizer_tfidf.transform(texts)\n",
        "        return best_lr_model.predict_proba(texts_tfidf)\n",
        "\n",
        "    # Explicar algumas amostras\n",
        "    print(\"\\n--- LIME Explanations (Logistic Regression) ---\")\n",
        "\n",
        "    for i in range(min(3, len(sample_texts))):  # Explicar apenas 3 amostras\n",
        "        try:\n",
        "            # Gerar explicação\n",
        "            exp = explainer_lime.explain_instance(\n",
        "                sample_texts[i],\n",
        "                predict_proba_lr,\n",
        "                num_features=10,\n",
        "                num_samples=1000\n",
        "            )\n",
        "\n",
        "            # Mostrar explicação\n",
        "            print(f\"\\nAmostra {i+1} (Label Real: {sample_labels[i]}):\")\n",
        "            print(\"Texto:\", sample_texts[i][:200] + \"...\" if len(sample_texts[i]) > 200 else sample_texts[i])\n",
        "            print(\"\\nPalavras mais importantes:\")\n",
        "            for word, importance in exp.as_list():\n",
        "                print(f\"  {word}: {importance:.4f}\")\n",
        "\n",
        "            # Visualização HTML (opcional)\n",
        "            exp.save_to_file(f'lime_explanation_sample_{i+1}.html')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro na explicação LIME para amostra {i+1}: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 4. ANÁLISE COMPARATIVA DE FEATURES IMPORTANTES\n",
        "# ================================================\n",
        "\n",
        "def analyze_important_features():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ANÁLISE DE FEATURES IMPORTANTES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 4.1 Features importantes do Logistic Regression\n",
        "    print(\"\\n--- Top Features - Logistic Regression ---\")\n",
        "    feature_names = vectorizer_tfidf.get_feature_names_out()\n",
        "    coefficients = best_lr_model.coef_[0]\n",
        "\n",
        "    # Top features positivas e negativas\n",
        "    top_positive = np.argsort(coefficients)[-15:][::-1]\n",
        "    top_negative = np.argsort(coefficients)[:15]\n",
        "\n",
        "    print(\"Top 15 palavras para classe POSITIVA:\")\n",
        "    for idx in top_positive:\n",
        "        print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "    print(\"\\nTop 15 palavras para classe NEGATIVA:\")\n",
        "    for idx in top_negative:\n",
        "        print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "    # 4.2 Feature importance do Random Forest\n",
        "    print(\"\\n--- Feature Importance - Random Forest ---\")\n",
        "    rf_importance = best_rf_model.feature_importances_\n",
        "    top_rf_features = np.argsort(rf_importance)[-15:][::-1]\n",
        "\n",
        "    print(\"Top 15 dimensões mais importantes (Word2Vec):\")\n",
        "    for i, idx in enumerate(top_rf_features):\n",
        "        print(f\"  Dimensão {idx}: {rf_importance[idx]:.4f}\")\n",
        "\n",
        "    # 4.3 Feature importance do XGBoost\n",
        "    print(\"\\n--- Feature Importance - XGBoost ---\")\n",
        "    xgb_importance = best_xgb_model.feature_importances_\n",
        "    top_xgb_features = np.argsort(xgb_importance)[-15:][::-1]\n",
        "\n",
        "    print(\"Top 15 dimensões mais importantes (GloVe):\")\n",
        "    for i, idx in enumerate(top_xgb_features):\n",
        "        print(f\"  Dimensão {idx}: {xgb_importance[idx]:.4f}\")\n",
        "\n",
        "# ================================================\n",
        "# 5. VISUALIZAÇÕES AVANÇADAS\n",
        "# ================================================\n",
        "\n",
        "def create_advanced_visualizations():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"VISUALIZAÇÕES AVANÇADAS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # 5.1 WordCloud das palavras mais importantes\n",
        "    try:\n",
        "        feature_names = vectorizer_tfidf.get_feature_names_out()\n",
        "        coefficients = best_lr_model.coef_[0]\n",
        "\n",
        "        # Criar dicionário para WordCloud\n",
        "        word_importance = {}\n",
        "        top_indices = np.argsort(np.abs(coefficients))[-100:]  # Top 100 palavras\n",
        "\n",
        "        for idx in top_indices:\n",
        "            word_importance[feature_names[idx]] = abs(coefficients[idx])\n",
        "\n",
        "        # Gerar WordCloud\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # WordCloud para palavras positivas\n",
        "        plt.subplot(1, 2, 1)\n",
        "        positive_words = {word: coef for word, coef in word_importance.items()\n",
        "                         if coefficients[np.where(feature_names == word)[0][0]] > 0}\n",
        "        if positive_words:\n",
        "            wc_pos = WordCloud(width=600, height=400, background_color='white').generate_from_frequencies(positive_words)\n",
        "            plt.imshow(wc_pos, interpolation='bilinear')\n",
        "            plt.title('Palavras Importantes - Sentimento POSITIVO')\n",
        "            plt.axis('off')\n",
        "\n",
        "        # WordCloud para palavras negativas\n",
        "        plt.subplot(1, 2, 2)\n",
        "        negative_words = {word: coef for word, coef in word_importance.items()\n",
        "                         if coefficients[np.where(feature_names == word)[0][0]] < 0}\n",
        "        if negative_words:\n",
        "            wc_neg = WordCloud(width=600, height=400, background_color='white').generate_from_frequencies(negative_words)\n",
        "            plt.imshow(wc_neg, interpolation='bilinear')\n",
        "            plt.title('Palavras Importantes - Sentimento NEGATIVO')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na criação do WordCloud: {e}\")\n",
        "\n",
        "    # 5.2 Comparação de importância entre modelos\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Normalizar importâncias para comparação\n",
        "        lr_importance_norm = np.abs(coefficients) / np.max(np.abs(coefficients))\n",
        "        rf_importance_norm = rf_importance / np.max(rf_importance)\n",
        "        xgb_importance_norm = xgb_importance / np.max(xgb_importance)\n",
        "\n",
        "        # Plotar distribuições\n",
        "        plt.hist(lr_importance_norm, bins=50, alpha=0.7, label='Logistic Regression', density=True)\n",
        "        plt.hist(rf_importance_norm, bins=50, alpha=0.7, label='Random Forest', density=True)\n",
        "        plt.hist(xgb_importance_norm, bins=50, alpha=0.7, label='XGBoost', density=True)\n",
        "\n",
        "        plt.xlabel('Importância Normalizada')\n",
        "        plt.ylabel('Densidade')\n",
        "        plt.title('Distribuição de Importância das Features por Modelo')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro na comparação de importâncias: {e}\")\n",
        "\n",
        "# ================================================\n",
        "# 6. EXECUTAR ANÁLISES\n",
        "# ================================================\n",
        "\n",
        "def run_explainability_analysis():\n",
        "    \"\"\"Executar toda a análise de explicabilidade\"\"\"\n",
        "\n",
        "    print(\"Iniciando análise de explicabilidade...\")\n",
        "\n",
        "    # Executar SHAP\n",
        "    explain_with_shap()\n",
        "\n",
        "    # Executar LIME (comparação)\n",
        "    explain_with_lime()\n",
        "\n",
        "    # Analisar features importantes\n",
        "    analyze_important_features()\n",
        "\n",
        "    # Criar visualizações avançadas\n",
        "    create_advanced_visualizations()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESUMO DA ANÁLISE DE EXPLICABILIDADE\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\"\"\n",
        "    ✅ SHAP Analysis:\n",
        "       - Fornece explicações baseadas em valores Shapley\n",
        "       - Mostra contribuição de cada feature para predições individuais\n",
        "       - Permite comparação entre diferentes modelos\n",
        "\n",
        "    ✅ LIME Analysis:\n",
        "       - Oferece explicações locais interpretáveis\n",
        "       - Útil para entender predições específicas\n",
        "       - Funciona bem com dados de texto\n",
        "\n",
        "    ✅ Feature Importance:\n",
        "       - Identifica palavras/dimensões mais relevantes\n",
        "       - Compara importância entre diferentes representações\n",
        "       - Ajuda na interpretação do modelo\n",
        "\n",
        "    💡 Recomendação: Use SHAP para análise geral e LIME para casos específicos\n",
        "    \"\"\")\n",
        "\n",
        "# Executar a análise completa\n",
        "if __name__ == \"__main__\":\n",
        "    run_explainability_analysis()"
      ],
      "metadata": {
        "id": "rdVbzMVEMnal"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69216df7ecf44c0ba878a93c1530ebcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a00c936f5c2440a1bf6eb8860a29d9c9",
              "IPY_MODEL_0ad01008b409438da136de0eeaa8378f",
              "IPY_MODEL_95a363294aa64993b28471a614da97ef"
            ],
            "layout": "IPY_MODEL_b904633988434cb782b8c2fc4d31b870"
          }
        },
        "a00c936f5c2440a1bf6eb8860a29d9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dafa6dcb99d546eeb7e6008cbbaa9f8a",
            "placeholder": "​",
            "style": "IPY_MODEL_b68305c0b4794aacacec797abec699d9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0ad01008b409438da136de0eeaa8378f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a7892dda95456d860da010511e36b4",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f240cd219d1a4540ad7c7b9379253cbe",
            "value": 48
          }
        },
        "95a363294aa64993b28471a614da97ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6208cd3114384e9ebc27e9e107ffd429",
            "placeholder": "​",
            "style": "IPY_MODEL_8017d3670bb24ce1a13535be5a632ab6",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.52kB/s]"
          }
        },
        "b904633988434cb782b8c2fc4d31b870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafa6dcb99d546eeb7e6008cbbaa9f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68305c0b4794aacacec797abec699d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a7892dda95456d860da010511e36b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f240cd219d1a4540ad7c7b9379253cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6208cd3114384e9ebc27e9e107ffd429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8017d3670bb24ce1a13535be5a632ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24f2f5aa11f4287aa6fd9e00e88dac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae8536e81bc24759ad1067a80be3937b",
              "IPY_MODEL_b1f8c37fe40946c0ad3d5a30beba9986",
              "IPY_MODEL_7dd05fa3eb2044498840326170541925"
            ],
            "layout": "IPY_MODEL_e177e5212d08444eabbd23d778463879"
          }
        },
        "ae8536e81bc24759ad1067a80be3937b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38bd088993d24bf4a7ff6c03eecc8e27",
            "placeholder": "​",
            "style": "IPY_MODEL_ec85cc8ec3314b0ba21286ea017e6a62",
            "value": "vocab.txt: 100%"
          }
        },
        "b1f8c37fe40946c0ad3d5a30beba9986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f386e360b30494ea04a38e036e0fc05",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11d793e01e744d2ab230bf3ecb882dee",
            "value": 231508
          }
        },
        "7dd05fa3eb2044498840326170541925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dffa3931cd540e8aae943de6d1fc475",
            "placeholder": "​",
            "style": "IPY_MODEL_3775c470eb2b477191ecaa65a855f0ba",
            "value": " 232k/232k [00:00&lt;00:00, 4.36MB/s]"
          }
        },
        "e177e5212d08444eabbd23d778463879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38bd088993d24bf4a7ff6c03eecc8e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec85cc8ec3314b0ba21286ea017e6a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f386e360b30494ea04a38e036e0fc05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d793e01e744d2ab230bf3ecb882dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dffa3931cd540e8aae943de6d1fc475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3775c470eb2b477191ecaa65a855f0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a057d9f84b6d4aeca91000746b39c668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94711dceb9484598a2c361321fd57809",
              "IPY_MODEL_8532749ce1dd4a3e906e513142b58866",
              "IPY_MODEL_1fdbf2e6b1ba459f8e9b410403c3652c"
            ],
            "layout": "IPY_MODEL_3587ed801fb944548898f6f9d06a9bde"
          }
        },
        "94711dceb9484598a2c361321fd57809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26e0d239cf54b149e8b5bd769b47b6a",
            "placeholder": "​",
            "style": "IPY_MODEL_8ac7cccdbb81406783e1bebdec27739a",
            "value": "tokenizer.json: 100%"
          }
        },
        "8532749ce1dd4a3e906e513142b58866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1196076846e4c42b9921c01c5ed0a50",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa87ecd7bd884036a71cb15235f713d4",
            "value": 466062
          }
        },
        "1fdbf2e6b1ba459f8e9b410403c3652c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e641e50708334cb6ada8348a9c781260",
            "placeholder": "​",
            "style": "IPY_MODEL_e638c9acf88a469c8ddbbe982be926f2",
            "value": " 466k/466k [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "3587ed801fb944548898f6f9d06a9bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26e0d239cf54b149e8b5bd769b47b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac7cccdbb81406783e1bebdec27739a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1196076846e4c42b9921c01c5ed0a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa87ecd7bd884036a71cb15235f713d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e641e50708334cb6ada8348a9c781260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e638c9acf88a469c8ddbbe982be926f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac98e4066b5d4a06a5ce45d86b6b01e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0f6ae52d67448adab9e630c5e61ab48",
              "IPY_MODEL_0753e3136ce84c10a5669f792cb6fece",
              "IPY_MODEL_e3bc6f9dc542445bb40ac8524ad84ef2"
            ],
            "layout": "IPY_MODEL_1e5897fb55bb4b9b9e734c643ca4a91a"
          }
        },
        "b0f6ae52d67448adab9e630c5e61ab48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb99e3d93ba34c85a67bd5b317ee2842",
            "placeholder": "​",
            "style": "IPY_MODEL_1eec6b08fe5040d88f8f470ac899677f",
            "value": "config.json: 100%"
          }
        },
        "0753e3136ce84c10a5669f792cb6fece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44390415c3946cfa19835389a6d1e8d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40b162589d41435cad0a6c23a60d59ef",
            "value": 570
          }
        },
        "e3bc6f9dc542445bb40ac8524ad84ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864adc25079145fc8facaba484ec4bc3",
            "placeholder": "​",
            "style": "IPY_MODEL_b9afe98c956140b2bc0bd0d6b4d6dddc",
            "value": " 570/570 [00:00&lt;00:00, 32.4kB/s]"
          }
        },
        "1e5897fb55bb4b9b9e734c643ca4a91a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb99e3d93ba34c85a67bd5b317ee2842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eec6b08fe5040d88f8f470ac899677f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44390415c3946cfa19835389a6d1e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40b162589d41435cad0a6c23a60d59ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "864adc25079145fc8facaba484ec4bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9afe98c956140b2bc0bd0d6b4d6dddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "395f34276a3d4bf18badf99ab98e3d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95e14e4902e64c109f3f6324e0e8cc90",
              "IPY_MODEL_ff7d62c0d56446d686dca272d411dd8c",
              "IPY_MODEL_142255d417d64fefb6a81aaa22f19412"
            ],
            "layout": "IPY_MODEL_d4b53be33fce4648a78ea937ab4e7513"
          }
        },
        "95e14e4902e64c109f3f6324e0e8cc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8cbc107e90d4644bcd8f9bcb7f16cac",
            "placeholder": "​",
            "style": "IPY_MODEL_d1d0f3978a424b92afb85b42effc63ba",
            "value": "model.safetensors: 100%"
          }
        },
        "ff7d62c0d56446d686dca272d411dd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62a380a40d0493684fc5fa625933253",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f9058f327a040118404ea765474b5ae",
            "value": 440449768
          }
        },
        "142255d417d64fefb6a81aaa22f19412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d438e0833f40a99690aa0628fb2f2a",
            "placeholder": "​",
            "style": "IPY_MODEL_72b5258f2d024e0a9d3d12c4d4f78bcf",
            "value": " 440M/440M [00:16&lt;00:00, 21.6MB/s]"
          }
        },
        "d4b53be33fce4648a78ea937ab4e7513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8cbc107e90d4644bcd8f9bcb7f16cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d0f3978a424b92afb85b42effc63ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e62a380a40d0493684fc5fa625933253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f9058f327a040118404ea765474b5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07d438e0833f40a99690aa0628fb2f2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b5258f2d024e0a9d3d12c4d4f78bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}